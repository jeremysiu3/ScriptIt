{"pageid": 1495156, "title": "ভাষার মডেল", "url": "https://bn.wikipedia.org/wiki?curid=1495156", "content": "একটি ভাষার মডেল প্রাকৃতিক ভাষার একটি সম্ভাব্য মডেল । ১৯৮০ সালে প্রথম উল্লেখযোগ্য পরিসংখ্যানগত ভাষার মডেল প্রস্তাব করা হয়েছিল এবং একই দশকে আইবিএম 'শ্যানন-শৈলী' পরীক্ষা-নিরীক্ষা করে, যেখানে পাঠ্যের ভবিষ্যদ্বাণী বা সংশোধনে মানব বিষয়ের কর্মক্ষমতা পর্যবেক্ষণ ও বিশ্লেষণ করে ভাষার মডেলিং উন্নতির সম্ভাব্য উৎস চিহ্নিত করা হয়েছিল।\nভাষা মডেল বিভিন্ন কাজে উপযোগী, যার মধ্যে রয়েছে কণ্ঠ শনাক্তকরণ (যা কম সম্ভাবনাময়, যেমন অর্থহীন ক্রমের পূর্বাভাস ঠেকাতে সহায়ক), যন্ত্রানুবাদ, স্বাভাবিক ভাষা উৎপাদন (আরও মানবসদৃশ লেখা তৈরি করা), আলোকভিত্তিক অক্ষর শনাক্তকরণ, পথ নির্ধারণ, [হাতের লেখা শনাক্তকরণ, ব্যাকরণ আনয়ন এবং তথ্য পুনরুদ্ধার।\nবড় ডেটাসেট (প্রায়ই ইন্টারনেট থেকে স্ক্র্যাপ করা শব্দসমূহ), ফিডফরোয়ার্ড স্নায়ু নেটওয়ার্ক এবং ট্রান্সফরমারের সমন্বয়ে গঠিত বৃহৎ ভাষার মডেল বর্তমানে এটির সর্বাধিক উন্নত রূপ। এরা পুনরাবৃত্ত স্নায়ু নেটওয়ার্ক-ভিত্তিক মডেলের স্থান নিয়েছে, যা এর আগে বিশুদ্ধ পরিসংখ্যানভিত্তিক মডেল, যেমন শব্দ এন-গ্রাম ভাষা মডেলকে প্রতিস্থাপন করেছিল।\n\n\n== বিশুদ্ধ পরিসংখ্যান মডেল ==\n\n\n=== শব্দ এন-গ্রামের উপর ভিত্তি করে মডেল ===\nশব্দ এন-গ্রাম ভাষা মডেল একটি সম্পূর্ণ পরিসংখ্যানভিত্তিক ভাষার মডেল। এটি পুনরাবৃত্ত স্নায়ু নেটওয়ার্ক–ভিত্তিক মডেল দ্বারা প্রতিস্থাপিত হয়েছে, যা পরবর্তীতে বৃহৎ ভাষার মডেল দ্বারা প্রতিস্থাপিত হয়েছে। এই মডেল ধরে নেয় যে একটি ক্রমের পরবর্তী শব্দের সম্ভাব্যতা শুধুমাত্র একটি নির্দিষ্ট আকারের পূর্ববর্তী শব্দের উইন্ডোর উপর নির্ভরশীল। যদি মাত্র এক পূর্ববর্তী শব্দ বিবেচনা করা হয়, সেটি বিগ্রাম মডেল; দুই শব্দ হলে ট্রিগ্রাম মডেল; এবং এন−১ শব্দ হলে এন-গ্রাম মডেল। বাক্যের শুরু এবং শেষ নির্দেশ করতে বিশেষ টোকেন \n  \n    \n      \n        ⟨\n        s\n        ⟩\n      \n    \n    {\\displaystyle \\langle s\\rangle }\n  \n এবং \n  \n    \n      \n        ⟨\n        \n          /\n        \n        s\n        ⟩\n      \n    \n    {\\displaystyle \\langle /s\\rangle }\n  \n ব্যবহৃত হয়।\nঅদেখা শব্দের জন্য শূন্য সম্ভাবনা নির্ধারণ ঠেকাতে, প্রতিটি শব্দের সম্ভাবনা তার ফ্রিকোয়েন্সি কাউন্টের চেয়ে সামান্য কম রাখা হয়। এটি হিসাব করার জন্য বিভিন্ন পদ্ধতি ব্যবহৃত হয়েছে, যেমন সাদামাটা \"অ্যাড-ওয়ান\" স্মুথিং (অদেখা এন-গ্রামের জন্য ১ এর কাউন্ট নির্ধারণ করা, যা একটি অপ্রাসঙ্গিক প্রাকৃতিক অনুমান হিসেবে কাজ করে) থেকে আরও উন্নত মডেল, যেমন গুড-টারিং ডিসকাউন্টিং বা ব্যাক-অফ মডেল।\n\n\n=== সূচকীয় ===\nসর্বাধিক এনট্রপি ভাষার মডেল বৈশিষ্ট্য ফাংশন ব্যবহার করে একটি শব্দ এবং এন-গ্রাম ইতিহাসের মধ্যে সম্পর্ক এনকোড করে। সমীকরণ হল:\n\n  \n    \n      \n        P\n        (\n        \n          w\n          \n            m\n          \n        \n        ∣\n        \n          w\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          w\n          \n            m\n            −\n            1\n          \n        \n        )\n        =\n        \n          \n            1\n            \n              Z\n              (\n              \n                w\n                \n                  1\n                \n              \n              ,\n              …\n              ,\n              \n                w\n                \n                  m\n                  −\n                  1\n                \n              \n              )\n            \n          \n        \n        exp\n        ⁡\n        (\n        \n          a\n          \n            T\n          \n        \n        f\n        (\n        \n          w\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          w\n          \n            m\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle P(w_{m}\\mid w_{1},\\ldots ,w_{m-1})={\\frac {1}{Z(w_{1},\\ldots ,w_{m-1})}}\\exp(a^{T}f(w_{1},\\ldots ,w_{m}))}\n  \n\nযেখানে \n  \n    \n      \n        Z\n        (\n        \n          w\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          w\n          \n            m\n            −\n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle Z(w_{1},\\ldots ,w_{m-1})}\n  \n পার্টিশন ফাংশন হল, \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n পরামিতি ভেক্টর এবং \n  \n    \n      \n        f\n        (\n        \n          w\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          w\n          \n            m\n          \n        \n        )\n      \n    \n    {\\displaystyle f(w_{1},\\ldots ,w_{m})}\n  \n বৈশিষ্ট্য ফাংশন. সহজভাবে, বৈশিষ্ট্য ফাংশন একটি নির্দিষ্ট এন-গ্রাম উপস্থিতির একটি সূচক মাত্র। এটি একটি পূর্বে ব্যবহার সহায়ক \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n বা নিয়মিতকরণের কিছু রূপ।\nলগ-বিলিনিয়ার মডেল একটি সূচকীয় ভাষা মডেলের আরেকটি উদাহরণ।\n\n\n=== স্কিপ-গ্রাম মডেল ===\nস্কিপ-গ্রাম ভাষা মডেল একটি প্রচেষ্টা যা পূর্ববর্তী মডেল (অর্থাৎ শব্দ এন-গ্রাম ভাষা মডেল) যে ডেটা সংকট সমস্যার সম্মুখীন হয়েছিল তা কাটিয়ে উঠতে সাহায্য করে। এম্বেডিং ভেক্টরে উপস্থাপিত শব্দগুলি আর নির্দিষ্টভাবে পরপর থাকত না, বরং মাঝে গ্যাপ থাকতে পারত যেগুলি স্কিপ করা হত।\nআনুষ্ঠানিকভাবে, একটি k-স্কিপ-n-গ্রাম হলো একটি দৈর্ঘ্য-n এর সাবসিকোয়েন্স, যেখানে উপাদানগুলো একে অপরের থেকে সর্বোচ্চ k দূরত্বে থাকে।\nউদাহরণস্বরূপ, ইনপুট পাঠ্যে:\n\nthe rain in Spain falls mainly on the plain\n১-স্কিপ-২-গ্রামের সেটে সমস্ত বিগ্রাম (২-গ্রাম) এবং উপরন্তু পরবর্তীতে\n\nthe in, rain Spain, in falls, Spain mainly, falls on, mainly the, and on plain.\nস্কিপ-গ্রাম মডেলে, শব্দগুলির মধ্যে অর্থনৈতিক সম্পর্কগুলি রৈখিক সংমিশ্রণের মাধ্যমে উপস্থাপিত হয়, যা কম্পোজিশনালিটির একটি রূপ ধারণ করে। উদাহরণস্বরূপ, কিছু মডেলে, যদি v একটি ফাংশন হয় যা একটি শব্দ w কে তার n-ডি ভেক্টর উপস্থাপনায় রূপান্তরিত করে, তাহলে\n  \n    \n      \n        v\n        (\n        \n          k\n          i\n          n\n          g\n        \n        )\n        −\n        v\n        (\n        \n          m\n          a\n          l\n          e\n        \n        )\n        +\n        v\n        (\n        \n          f\n          e\n          m\n          a\n          l\n          e\n        \n        )\n        ≈\n        v\n        (\n        \n          q\n          u\n          e\n          e\n          n\n        \n        )\n      \n    \n    {\\displaystyle v(\\mathrm {king} )-v(\\mathrm {male} )+v(\\mathrm {female} )\\approx v(\\mathrm {queen} )}\n  \n\nযেখানে ≈ স্পষ্ট করা হয় এই শর্ত দিয়ে যে, এর ডানপাশের মানটি বামপাশের মানের কাছের প্রতিবেশী হতে হবে।\n\n\n== স্নায়ু মডেল ==\n\n\n=== পৌনঃপুনিক স্নায়ু নেটওয়ার্ক ===\nক্রমাগত উপস্থাপনা বা শব্দের এম্বেডিংগুলি পুনরাবৃত্ত স্নায়ু নেটওয়ার্ক-ভিত্তিক ভাষা মডেলগুলিতে উৎপাদিত হয় (যা ক্রমাগত স্পেস ল্যাঙ্গুয়েজ মডেল নামেও পরিচিত)। এই ধরনের ক্রমাগত স্পেস এম্বেডিং মাত্রিকতার সমস্যা দূর করতে সাহায্য করে, যা শব্দভান্ডারের আকারের সাথে দ্রুতগতিতে শব্দের সম্ভাব্য ক্রম সংখ্যা বৃদ্ধির ফলস্বরূপ, ডেটা স্প্যার্সিটি সমস্যা সৃষ্টি করে। স্নায়ু নেটওয়ার্কগুলি একটি স্নায়ু জালে ওজনের অ-রৈখিক সংমিশ্রণ হিসাবে শব্দগুলিকে উপস্থাপন করে এই সমস্যাটি এড়ায়।\n\n\n=== বড় ভাষার মডেল ===\nযদিও কখনও কখনও মানুষের কর্মক্ষমতা মিলে যায়, তবে তারা যুক্তিযুক্ত জ্ঞানীয় মডেল কিনা তা স্পষ্ট নয়। অন্তত পুনরাবৃত্ত স্নায়ু নেটওয়ার্কগুলির জন্য, এটি দেখানো হয়েছে যে তারা কখনও কখনও এমন নিদর্শন শিখে যা মানুষ করে না, কিন্তু মানুষ সাধারণত যে নিদর্শনগুলি করে তা শিখতে ব্যর্থ হয়।\n\n\n== মূল্যায়ন এবং মানদণ্ড ==\nভাষার মডেলের গুণমানের মূল্যায়ন বেশিরভাগই সাধারণ ভাষা-ভিত্তিক কাজ থেকে তৈরি মানুষের তৈরি নমুনা বেঞ্চমার্কের সাথে তুলনা করে করা হয়। অন্যদিকে (কম প্রতিষ্ঠিত পদ্ধতি) গুণমানের পরীক্ষাগুলি একটি ভাষা মডেলের অন্তর্নিহিত চরিত্র পরীক্ষা করে বা এই জাতীয় দুটি মডেলের তুলনা করে। যেহেতু ভাষার মডেলগুলি সাধারণত গতিশীল হতে এবং তারা যে ডেটা দেখে তা থেকে শেখার উদ্দেশ্যে করা হয়, তাই কিছু প্রস্তাবিত মডেল শেখার হারের তদন্ত করে। যেমন- শেখার বক্ররেখা পরিদর্শনের মাধ্যমে।\nভাষা প্রক্রিয়াকরণ সিস্টেমের মূল্যায়নে ব্যবহারের জন্য বিভিন্ন ডেটাসেট তৈরি করা হয়েছে। এর মধ্যে রয়েছে:\n\nভাষাগত গ্রহণযোগ্যতার কর্পাস\nআঠালো বেঞ্চমার্ক\nমাইক্রোসফট রিসার্চ প্যারাফ্রেজ কর্পাস\nমাল্টি-জেনার ন্যাচারাল ল্যাঙ্গুয়েজ ইনফারেন্স\nপ্রশ্ন প্রাকৃতিক ভাষা ইনফারেন্স\nকোরা প্রশ্ন পেয়ার\nটেক্সচুয়াল এনটেইলমেন্ট স্বীকৃতি\nশব্দার্থিক টেক্সচুয়াল সাদৃশ্য বেঞ্চমার্ক\nস্কোয়াড প্রশ্নের উত্তর পরীক্ষা\nস্ট্যানফোর্ড সেন্টিমেন্ট ট্রিব্যাঙ্ক\nউইনোগ্রাড এনএলআই\nবুলকিউ, পিআইকিউএ, এসআইকিউএ, হেলাসোয়াগ, উইনোগ্রান্ডে, এআরসি, ওপেনবুককিউএ, ন্যাচারালকুয়েশন্স, ট্রিভিয়াকিউএ, রেস, এমএমএলইউ (ম্যাসিভ মাল্টিটাস্ক ল্যাঙ্গুয়েজ আন্ডারস্ট্যান্ডিং), বিগ-বেঞ্চ হার্ড, জিএসএম৮ক, রিয়েলটক্সিসিটি প্রম্পটস, উইনোজেন্ডার্স, (এলএলএমএ বেঞ্চমার্ক)।\n\n\n== আরও দেখুন ==\n \n\n\n== তথ্যসূত্র ==\n\n\n== আরও পড়ুন =="}