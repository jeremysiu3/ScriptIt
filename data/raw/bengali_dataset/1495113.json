{"pageid": 1495113, "title": "বৃহৎ ভাষার মডেল", "url": "https://bn.wikipedia.org/wiki?curid=1495113", "content": "বৃহৎ ভাষার মডেল এক ধরনের গণনামূলক মডেল যা ভাষা তৈরির মতো প্রাকৃতিক ভাষা প্রক্রিয়াকরণের জন্য প্রস্তুত করা হয়েছে। ইংরেজিতে একে লার্জ ল্যাঙ্গুয়েজ মডেল বলা হয়, যার সংক্ষেপিত সংস্করণ- এলএলএম। ভাষার মডেল হিসাবে, এলএলএম একটি স্ব-তত্ত্বাবধানে এবং অর্ধ-তত্ত্বাবধানে প্রশিক্ষণ প্রক্রিয়া চলাকালীন প্রচুর পরিমাণে পাঠ্য থেকে পরিসংখ্যানগত সম্পর্ক শেখার মাধ্যমে এই ক্ষমতাগুলি অর্জন করে।\nসবচেয়ে বড় এবং সবচেয়ে সক্ষম এলএলএম হল কৃত্রিম নিউরাল নেটওয়ার্ক যা একটি শুধু-ডিকোডার ট্রান্সফরমার-ভিত্তিক স্থাপত্য দিয়ে তৈরি, যা দক্ষ প্রক্রিয়াকরণ এবং বড় আকারের পাঠ্য ডেটা তৈরি করতে সক্ষম করে। আধুনিক মডেলগুলি নির্দিষ্ট কাজের জন্য সূক্ষ্মতর উন্নয়ন করা যেতে পারে বা প্রম্পট ইঞ্জিনিয়ারিং দ্বারা পরিচালিত হতে পারে। এই মডেলগুলি বাক্যতত্ত্ব, বাগর্থবিজ্ঞান এবং অনটোলজি সম্পর্কিত ভবিষ্যদ্বাণীমূলক শক্তি অর্জন করে যা মানব ভাষার কর্পোরার অন্তর্নিহিত, কিন্তু তারা যে ডেটাতে প্রশিক্ষিত হয় তাতে উপস্থিত ভুলসমূহ এবং পক্ষপাতগুলিও উত্তরাধিকার সূত্রে পায়।\n\n\n== ইতিহাস ==\n\n২০১৭ সালের আগে কিছু ভাষার মডেল ছিল, যা তখন উপলব্ধ ক্ষমতার তুলনায় বড় ছিল। ১৯৯০-এর দশকে, আইবিএম অ্যালাইনমেন্ট মডেলগুলি পরিসংখ্যানগত ভাষা মডেলিংয়ের পথপ্রদর্শক। ২০০১ সালে ৩০ কোটি শব্দের উপর প্রশিক্ষিত একটি মসৃণ এন-গ্রাম মডেল সেই সময়ে অত্যাধুনিক বিভ্রান্তি অর্জন করেছিল। ২০০০-এর দশকে, যখন ইন্টারনেট ব্যবহার প্রচলিত হয়ে ওঠে, কিছু গবেষক ইন্টারনেট-স্কেল ল্যাঙ্গুয়েজ ডেটাসেট (\"কর্পাস হিসেবে ওয়েব\") তৈরি করেছিলেন, যার ভিত্তিতে তারা পরিসংখ্যানগত ভাষার মডেলগুলিকে প্রশিক্ষণ দিয়েছিলেন। ২০০৯ সালে, বেশিরভাগ ভাষা প্রক্রিয়াকরণের কাজগুলিতে পরিসংখ্যানগত ভাষার মডেলগুলি প্রতীকী ভাষার মডেলগুলির উপর আধিপত্য বিস্তার করে, কারণ তারা দরকারীভাবে বড় ডেটাসেটগুলি গ্রহণ করতে সক্ষম।\n২০১২ সালের দিকে যখন নিউরাল নেটওয়ার্কগুলি চিত্র প্রক্রিয়াকরণের ক্ষেত্রে প্রাধান্য পেতে শুরু করে, তখন এগুলিকে ভাষা মডেলিংয়ের ক্ষেত্রেও ব্যবহার করা হতে থাকে। ২০১৬ সালে গুগল তার অনুবাদ সেবা নিউরাল মেশিন ট্রান্সলেশনে (এনএমটি) রূপান্তরিত করে। এটি ট্রান্সফরমার প্রযুক্তির আগের সময়ের ঘটনা এবং তখন এটি করা হয়েছিল সিকুয়েন্স টু সিকুয়েন্স (seq2seq) গভীর এলএসটিএম নেটওয়ার্কের মাধ্যমে।\n২০১৭ সালের নিউরআইপিএস কনফারেন্স, গুগলের গবেষকরা তাদের গুরুত্বপূর্ণ প্রবন্ধ \"মনোযোগ ইজ অল ইউ নিড\" এ ট্রান্সফরমার স্থাপত্যটি উপস্থাপন করেন। এই প্রবন্ধের লক্ষ্য ছিল ২০১৪ সালের সিক২সিক (seq2seq) প্রযুক্তির উন্নতি করা। এটি মূলত ২০১৪ সালে বাহদানাউ এট আল. দ্বারা ডেভেলপ করা মনোযোগ পদ্ধতির উপর ভিত্তি করে ছিল। পরবর্তী বছর ২০১৮ সালে, বার্ট উপস্থাপিত হয় এবং দ্রুত \"সর্বব্যাপী\" হয়ে ওঠে। যদিও মূল ট্রান্সফরমারে এনকোডার এবং ডিকোডার উভয় ব্লক ছিল, কিন্তু বার্ট একটি শুধু-এনকোডার মডেল।\n\nযদিও ২০১৮ সালে শুধু-ডিকোডার জিপিটি-১ উপস্থাপন করা হয়েছিল, ২০১৯ সালে জিপিটি-২ ব্যাপক মনোযোগ আকর্ষণ করে কারণ ওপেনএআই প্রথমে এটি জনসাধারণের কাছে মুক্তি দেওয়ার জন্য খুব শক্তিশালী মনে করেছিল, ক্ষতিকর ব্যবহারের আশঙ্কায়। ২০২০ সালে জিপিটি-৩ আরও একধাপ এগিয়ে গিয়ে ২০২৪-এর হিসাব অনুযায়ী শুধুমাত্র এপিআই মাধ্যমে পাওয়া যাচ্ছে এবং মডেলটি স্থানীয়ভাবে ডাউনলোড করে চালানোর সুযোগ নেই। তবে, ২০২২ সালে ব্যবহারকারীদের জন্য উন্মুক্ত ব্রাউজার-ভিত্তিক চ্যাটজিপিটি সাধারণ জনগণের আগ্রহ আকর্ষণ করে এবং কিছু মিডিয়া হাইপ ও অনলাইনে গুঞ্জন সৃষ্টি করে। ২০২৩ সালের জিপিটি-৪ তার বৃদ্ধি পাওয়া নির্ভুলতা এবং বহুমাত্রিক সক্ষমতার জন্য প্রশংসিত হয় এবং একে \"পবিত্র রহস্য\" হিসেবে বিবেচনা করা হয়। ওপেনএআই জিপিটি-৪ এর উচ্চ-স্তরের স্থাপত্য এবং প্যারামিটার সংখ্যা প্রকাশ করেনি।প্রতিযোগিতামূলক ভাষার মডেলগুলি বেশিরভাগ ক্ষেত্রেই জিপিটি সিরিজের সমান হতে চেষ্টা করেছে, কমপক্ষে প্যারামিটার সংখ্যা অনুযায়ী।\n২০২২ সাল থেকে, উৎস-উপলব্ধ মডেলগুলি জনপ্রিয়তা লাভ করছে, বিশেষ করে প্রথমে ব্লুম এবং এলএলএমএ এর মাধ্যমে, যদিও উভয়ই ব্যবহারের ক্ষেত্রে কিছু সীমাবদ্ধতা রয়েছে। মিস্ট্রাল কৃত্রিম বুদ্ধিমত্তার মডেল মিস্ট্রাল ৭বি এবং মিক্সট্রাল ৮এক্স৭বি অধিক নমনীয় অ্যাপাচি লাইসেন্সে রয়েছে। জুন ২০২৪-এর হিসাব অনুযায়ী, লামা ৩ ৭০ বিলিয়ন প্যারামিটার মডেলের নির্দেশনা অনুযায়ী সুনির্দিষ্টভাবে টিউন করা ভেরিয়েন্ট হচ্ছে সবচেয়ে শক্তিশালী ওপেন ভাষার মডেল, যা এলএমএসওয়াইএস চ্যাটবট এরিনা লিডারবোর্ড অনুযায়ী জিপিটি-৩.৫ এর চেয়ে শক্তিশালী, তবে জিপিটি-৪ এর চেয়ে কম শক্তিশালী।\n২০২৪ সালের হিসাব অনুযায়ী, সবচেয়ে বড় এবং শক্তিশালী মডেলগুলি সবই ট্রান্সফরমার স্থাপত্যের উপর ভিত্তি করে। কিছু সাম্প্রতিক বাস্তবায়ন অন্য স্থাপত্যের উপর ভিত্তি করে তৈরি, যেমন পুনরাবৃত্ত স্নায়ু নেটওয়ার্ক ভেরিয়েন্ট এবং মাম্বা (একটি স্টেট স্পেস মডেল)।\n\n\n== ডেটাসেট প্রক্রিয়াকরণ ==\n\n\n=== টোকেনাইজেশন ===\n\nযেহেতু মেশিন লার্নিং অ্যালগরিদমগুলি সংখ্যা প্রক্রিয়া করে, পাঠ্যকে সংখ্যায় রূপান্তর করা প্রয়োজন হয়। প্রথম ধাপে, একটি শব্দকোষ নির্ধারণ করা হয়, তারপর প্রতিটি শব্দকোষ ভুক্তির জন্য এককভাবে কিন্তু এলোমেলোভাবে পূর্ণসংখ্যার সূচক নির্ধারিত হয়। এরপর পূর্ণসংখ্যার সূচকের সাথে একটি এমবেডিং যুক্ত করা হয়। অ্যালগরিদমগুলির মধ্যে রয়েছে বাইট-পেয়ার এনকোডিং (বিপিই) এবং শব্দখন্ড। এছাড়া কিছু বিশেষ টোকেন রয়েছে যা কন্ট্রোল ক্যারেক্টার হিসেবে কাজ করে, যেমন [MASK] মাক্সড আউট টোকেন (যা বার্টে ব্যবহৃত হয়), এবং [UNK] (\"অজানা\") শব্দকোষে না পাওয়া অক্ষরের জন্য ব্যবহৃত হয়। এছাড়া কিছু বিশেষ চিহ্ন রয়েছে যা বিশেষ পাঠ্য ফরম্যাটিং নির্দেশ করতে ব্যবহৃত হয়। উদাহরণস্বরূপ, \"Ġ\" রোবার্টা এবং জিপিটিতে পূর্ববর্তী সাদা স্থান নির্দেশ করে। \"##\" বার্টে পূর্ববর্তী শব্দের ধারাবাহিকতা নির্দেশ করে।\nউদাহরণস্বরূপ, জিপিটি-৩ (পুরাতন) tokenizer: texts -> series of numerical \"tokens\" কে ভেঙ্গে বিপিই টোকেনাইজার ব্যবহার করে নিম্নরূপে ব্যবহার করবে:\n\nটোকেনাইজেশন ডেটাসেটগুলিকে সংকুচিতও করে। যেহেতু সাধারণত এলএলএমগুলো ইনপুট হিসেবে এমন একটি অ্যারে প্রয়োজন যা অসমতল না হয়, ছোট পাঠ্যগুলোকে \"প্যাড\" করা হয় যতক্ষণ না সেগুলো সবচেয়ে দীর্ঘ পাঠ্যের দৈর্ঘ্য মেলে। প্রতিটি শব্দের জন্য গড়ে কতটুকু টোকেন প্রয়োজন, তা ডেটাসেটের ভাষার উপর নির্ভর করে।\n\n\n==== বিপিই ====\n\nএকটি উদাহরণ হিসেবে, বাইট-পেয়ার এনকোডিং ভিত্তিক একটি টোকেনাইজার বিবেচনা করা যাক। প্রথম ধাপে, সমস্ত অনন্য অক্ষর (সাদা স্থান এবং যতিচিহ্ন) একটি প্রাথমিক এন-গ্রাম সেট (অর্থাৎ, প্রাথমিক ইউনিগ্রাম সেট) হিসেবে বিবেচিত হয়। পরবর্তী ধাপে, সবচেয়ে বেশি উপস্থিত থাকা দুইটি পাশবর্তী অক্ষর একত্রিত হয়ে একটি বাই-গ্রামে পরিণত হয় এবং সেই জোড়া দিয়ে সমস্ত উদাহরণ প্রতিস্থাপিত হয়। তারপর, যেসব পূর্ববর্তী মিলিত এন-গ্রাম একে অপরের সাথে সবচেয়ে বেশি মিলিত হয়, সেগুলো আবার একত্রিত হয়ে আরও দীর্ঘ এন-গ্রামে পরিণত হয়, যতক্ষণ না একটি নির্দিষ্ট আকারের শব্দকোষ পাওয়া যায় (জিপিটি-৩ এর ক্ষেত্রে, আকারটি ৫০২৫৭)। টোকেনাইজার প্রশিক্ষিত হওয়ার পর, যে কোনো পাঠ্য এটিতে টোকেনাইজ করা যেতে পারে, যতক্ষণ না এতে প্রাথমিক ইউনিগ্রাম সেটে না পাওয়া অক্ষর থাকে।\n\n\n==== সমস্যা ====\nএকটি টোকেন শব্দকোষ যা মূলত ইংরেজি করপাস থেকে নিষ্কৃত ফ্রিকোয়েন্সির ভিত্তিতে তৈরি, গড়ে একটি ইংরেজি শব্দের জন্য যতটা সম্ভব কম টোকেন ব্যবহার করে। তবে, এমন একটি ইংরেজি-অপটিমাইজড টোকেনাইজার দ্বারা অন্য কোনো ভাষার গড়ে একটি শব্দকে কোড করা হলে, তা সাবঅপটিমাল পরিমাণ টোকেন-এ বিভক্ত হয়ে যায়। উদাহরণস্বরূপ, জিপিটি-২ টোকেনাইজার কিছু ভাষার জন্য শব্দপ্রতি ১৫ গুণ বেশি টোকেন ব্যবহার করতে পারে, যেমন মিয়ানমারের শান ভাষার জন্য। এমনকি আরও ব্যাপক ব্যবহৃত ভাষাগুলোর মতো পর্তুগিজ এবং জার্মান ভাষার জন্য ইংরেজির তুলনায় \"৫০% বেশি\" টোকেন ব্যবহার করতে হয়।\nলালচে (গ্রিডি) টোকেনাইজেশন পাঠ্য সম্পূর্ণ করার ক্ষেত্রে সূক্ষ্ম সমস্যাও সৃষ্টি করে।\n\n\n=== ডেটাসেট পরিষ্কারকরণ ===\n\nএলএলএম প্রশিক্ষণের প্রেক্ষাপটে, সাধারণত ডেটাসেটগুলো পরিষ্কার করা হয়। যাতে বিপজ্জনক অংশগুলো বাদ দেওয়া হয়, নিম্নমানের ডেটা ফেলে দেওয়া হয় এবং ডুপ্লিকেশন দূর করা হয়। পরিষ্কার করা ডেটাসেট প্রশিক্ষণের দক্ষতা বাড়াতে পারে এবং পরবর্তী কার্যকারিতায় উন্নতি ঘটাতে পারে। একটি প্রশিক্ষিত এলএলএম অন্য একটি এলএলএম প্রশিক্ষণের জন্য ডেটাসেট পরিষ্কার করতে ব্যবহার করা যেতে পারে।\nওয়েবে এলএলএম-উৎপন্ন বিষয়বস্তুের পরিমাণ বাড়ানোর পাশাপাশি ভবিষ্যতে ডেটা পরিষ্কারের প্রক্রিয়ায় এমন বিষয়বস্তু ছাঁকনি করা অন্তর্ভুক্ত হতে পারে। এলএলএম-উৎপন্ন বিষয়বস্তু সমস্যা সৃষ্টি করতে পারে যদি বিষয়বস্তুটি মানুষের লেখা পাঠ্যের মতো হয় (যা ছাঁকনি করা কঠিন করে তোলে) কিন্তু এর গুণমান কম হয় (যা এতে প্রশিক্ষিত মডেলগুলোর কার্যকারিতা হ্রাস করে)।\n\n\n=== সিন্থেটিক ডেটা ===\n\nসবচেয়ে বড় ভাষা মডেলের প্রশিক্ষণের জন্য স্বাভাবিকভাবে উপলব্ধের চেয়ে বেশি ভাষাগত ডেটার প্রয়োজন হতে পারে অথবা স্বাভাবিকভাবে প্রাপ্ত ডেটা অপর্যাপ্ত মানের হতে পারে। সেক্ষেত্রে সিন্থেটিক ডেটা ব্যবহার করা যেতে পারে। মাইক্রোসফটের ফি (Phi) সিরিজের এলএলএমগুলি অন্য এলএলএম দ্বারা তৈরি পাঠ্যপুস্তকের মতো ডেটার উপর প্রশিক্ষিত।\n\n\n== প্রশিক্ষণ ও স্থাপত্য ==\n\n\n=== মানুষের প্রতিক্রিয়া থেকে উন্নততর প্রশিক্ষণ (আরএলএইচএফ) ===\n\nমানুষের প্রতিক্রিয়া থেকে উন্নততর প্রশিক্ষণ বা রিইনফোর্সমেন্ট লার্নিং ফ্রম হিউম্যান ফিডব্যাক (আরএলএইচএফ) অ্যালগরিদমের মাধ্যমে (যেমন- প্রক্সিমাল পলিসি অপ্টিমাইজেশন) মানুষের পছন্দের ডেটাসেটের উপর ভিত্তি করে একটি মডেলকে আরও সূক্ষ্মভাবে উন্নত করতে ব্যবহৃত হয়।\n\n\n=== নির্দেশনা উন্নয়ন ===\n\"স্ব-নির্দেশনা\" পদ্ধতি ব্যবহার করে এলএলএমগুলো সঠিক উত্তর তৈরি করতে সক্ষম হয়েছে। এটি পূর্বের যে কোন সরল বা ভুল উত্তর প্রতিস্থাপন করে। এটি শুরু হয় কিছু মানব-উৎপন্ন সংশোধনী থেকে। উদাহরণস্বরূপ, যদি নির্দেশনা হয় \"হ্যামলেটের প্রধান থিমগুলো সম্পর্কে একটি প্রবন্ধ লিখুন\", তবে প্রাথমিকভাবে এলএলএম যে ভুল উত্তরটি দিতে পারে তা হতে পারে, \"যদি আপনি ১৭ মার্চের পর প্রবন্ধটি জমা দেন, তবে প্রতিদিন দেরির জন্য আপনার গ্রেড ১০% কমিয়ে দেওয়া হবে,\" যা মূলত প্রবন্ধের পরিবর্তে কোনও সাধারণ নিয়মের উপর ভিত্তি করে লেখা হয়, কারণ কর্পাসে এই ধরনের শব্দচয়ন বেশি পাওয়া যায়।\n\n\n=== বিশেষজ্ঞদের মিশ্রণ ===\n\nসবচেয়ে বড় এলএলএম প্রশিক্ষণ এবং সরাসরি ব্যবহার করার জন্য খুব ব্যয়বহুল হতে পারে। এই ধরনের মডেলগুলির জন্য বিশেষজ্ঞদের মিশ্রণ (এমওই) প্রয়োগ করা যেতে পারে। বিশেষজ্ঞদের মিশ্রণ পদ্ধতিটি ২০১৭ সাল থেকে গুগল গবেষকদের ১ ট্রিলিয়ন প্যারামিটার পর্যন্ত পৌঁছানোর মডেলগুলিকে প্রশিক্ষণ দেওয়ার জন্য গবেষণার একটি ধারা।\n\n\n=== প্রম্পট ইঞ্জিনিয়ারিং, মনোযোগের প্রক্রিয়া এবং প্রসঙ্গ উইন্ডো ===\n\nপূর্বে শুধুমাত্র (ব্যয়বহুল) ফাইন-টিউনিং এর মাধ্যমে অর্জন করা যায় এমন বেশিরভাগ ফলাফল প্রম্পট ইঞ্জিনিয়ারিং এর মাধ্যমে অর্জন করা যেতে পারে, যদিও এটি একক কথোপকথনের সুযোগের মধ্যে সীমাবদ্ধ (আরো সঠিকভাবে, একটি প্রসঙ্গ উইন্ডোর সুযোগের মধ্যে সীমাবদ্ধ)।\n\nকোন টোকেনগুলো একে অপরের সাথে সম্পর্কিত, তা জানতে প্রসঙ্গ উইন্ডোর মধ্যে মনোযোগ মেকানিজম প্রতিটি টোকেনের জন্য \"সফট\" ওজন হিসাব করে, যাকে বলা হয় টোকেনের এমবেডিং। এটি একাধিক মনোযোগ হেড ব্যবহার করে, যেখানে প্রতিটি হেডের নিজস্ব \"প্রাসঙ্গিকতা\" থাকে এবং এটি তার নিজস্ব সফট ওজন হিসাব করে। উদাহরণস্বরূপ, ছোট (১১৭ মিলিয়ন প্যারামিটার সাইজের) জিপিটি-২ মডেলটির ১২টি মনোযোগ হেড ছিল এবং এর প্রসঙ্গ উইন্ডো ছিল মাত্র ১ হাজার টোকেন। এর মাঝারি ভার্সনে ৩৪৫ মিলিয়ন প্যারামিটার রয়েছে এবং এতে ২৪টি লেয়ার রয়েছে, প্রতিটির মধ্যে ১২টি মনোযোগ হেড রয়েছে। প্রশিক্ষণের জন্য ৫১২ ব্যাচ সাইজ ব্যবহার করা হয়েছিল।\nবড় বড় মডেলগুলি, যেমন- ফেব্রুয়ারি ২০২৪-এ প্রকাশিত গুগলের জেমিনি ১.৫-এর প্রসঙ্গ উইন্ডো ১ মিলিয়ন টোকেন পর্যন্ত হতে পারে (এছাড়া ১০ মিলিয়ন প্রসঙ্গ উইন্ডোও \"সফলভাবে পরীক্ষা\" করা হয়েছে)। অন্যান্য বড় প্রসঙ্গ উইন্ডোযুক্ত মডেলগুলির মধ্যে রয়েছে অ্যানথ্রোপিকের ক্লোড ২.১, যার প্রসঙ্গ উইন্ডো ২০০,০০০ টোকেন পর্যন্ত হতে পারে। লক্ষ্য রাখতে হবে, এই সর্বাধিক সংখ্যা ইনপুট টোকেনের জন্য এবং আউটপুট টোকেনের সর্বাধিক সংখ্যা ইনপুটের থেকে আলাদা এবং সাধারণত ছোট হয়। উদাহরণস্বরূপ, জিপিটি-৪ টার্বো মডেলে আউটপুটের সর্বাধিক সংখ্যা ৪০৯৬ টোকেন। মডেলটির পরবর্তী উত্তর তৈরির জন্য যে আলাপচারিতার দৈর্ঘ্যটি মনে রাখা সম্ভব, তা প্রসঙ্গ উইন্ডোর আকার দ্বারা সীমিত। উদাহরণস্বরূপ, যদি চ্যাটজিপিটির সঙ্গে আলাপচারিতার দৈর্ঘ্য প্রসঙ্গ উইন্ডোর চেয়ে বেশি হয়, তাহলে কেবল প্রসঙ্গ উইন্ডোর মধ্যে থাকা অংশগুলোই পরবর্তী উত্তর তৈরির সময় বিবেচনা করা হয় অথবা মডেলটিকে আলাপচারিতার দূরের অংশগুলো সংক্ষেপে উপস্থাপন করতে কিছু অ্যালগরিদম প্রয়োগ করতে হতে পারে।\nপ্রসঙ্গ উইন্ডো বড় করার কিছু সীমাবদ্ধতা রয়েছে, যেমন এটি বেশি গণনামূলক খরচ তৈরি করতে পারে এবং স্থানীয় প্রসঙ্গে মনোযোগ কমিয়ে দিতে পারে, আবার প্রসঙ্গ উইন্ডো ছোট করলে মডেলটি গুরুত্বপূর্ণ দীর্ঘমেয়াদি সম্পর্ক উপেক্ষা করতে পারে। এগুলোর মধ্যে সঠিক সমন্বয় করা পরীক্ষামূলক এবং ক্ষেত্রভিত্তিক বিবেচনার বিষয়।\nসেগমেন্টটি কীভাবে চলতে থাকে তা অনুমান করার জন্য একটি মডেলকে পূর্বপ্রশিক্ষিত করা যেতে পারে অথবা সেগমেন্টে কী অনুপস্থিত, তার প্রশিক্ষণ ডেটাসেট থেকে একটি সেগমেন্ট দেওয়া হয়। এটা নিচের যেকোনো একটি হতে পারে:\n\nঅটোরিগ্রেসিভ (অথাৎ, সেগমেন্ট কিভাবে চলতে থাকবে তা পূর্বাভাস করা, যেমন জিপিটির কাজ): উদাহরণস্বরূপ, যদি সেগমেন্ট হয় \"I like to eat\", তাহলে মডেলটি ভবিষ্যদ্বাণী করতে পারে \"ice cream\" বা \"sushi\"।\nমাস্কড (অথাৎ, সেগমেন্টের অনুপস্থিত অংশ পূর্ণ করা, যেমন \"বার্ট\" মডেল করে থাকে): উদাহরণস্বরূপ, যদি সেগমেন্ট হয় \"I like to [__] [__] cream\", তবে মডেলটি পূর্বাভাস করতে পারে যে এখানে \"eat\" এবং \"ice\" অনুপস্থিত।\nমডেলগুলো সহায়ক কাজগুলোতে প্রশিক্ষিত হতে পারে, যা তাদের ডেটা বিতরণের বোঝাপড়া পরীক্ষা করে। যেমন নেক্সট সেন্টেন্স প্রেডিকশনে (এনএসপি) দুটি বাক্য প্রদর্শিত হয় এবং মডেলটিকে পূর্বাভাস করতে হয় যে, সেগুলি প্রশিক্ষণ কর্পাসে পরপর উপস্থিত কিনা। প্রশিক্ষণ চলাকালীন, প্রশিক্ষণ স্থিতিশীল রাখতে রেগুলারাইজেশন লস ব্যবহার করা হয়। তবে, পরীক্ষণ এবং মূল্যায়নের সময় সাধারণত রেগুলারাইজেশন লস ব্যবহার করা হয় না।\n\n\n=== অবকাঠামো ===\nসবচেয়ে বড় মডেলের প্রশিক্ষণের জন্য যথেষ্ট পরিকাঠামো প্রয়োজন।\n\n\n== প্রশিক্ষণ ব্যয় ==\n\nসফটওয়্যার এবং হার্ডওয়্যারের উন্নতির কারণে ২০২০ সাল থেকে খরচ অনেক কমে গেছে, এমনভাবে যে ২০২৩ সালে ১২ বিলিয়ন প্যারামিটারযুক্ত এলএলএম প্রশিক্ষণের কম্পিউটেশনাল খরচ হচ্ছে ৭২,৩০০ এ১০০-জিপিইউ-ঘণ্টা, যখন ২০২০ সালে ১.৫ বিলিয়ন প্যারামিটারযুক্ত এলএলএম (যা ২০২০ সালের প্রযুক্তির তুলনায় দুই শ্রেণী ছোট ছিল) প্রশিক্ষণের খরচ ছিল ৮০,০০০ ডলার থেকে ১৬,০০,০০০ ডলার পর্যন্ত। ২০২০ সাল থেকে, ক্রমবর্ধমান বড় মডেলগুলিতে বিপুল পরিমাণ অর্থ বিনিয়োগ করা হয়েছে। উদাহরণস্বরূপ, ২০১৯ সালে জিপিটি-২ (অর্থাৎ ১.৫ বিলিয়ন প্যারামিটার মডেল) প্রশিক্ষণের খরচ ছিল ৫০,০০০ ডলার, ২০২২ সালে পালম (অর্থাৎ ৫৪০ বিলিয়ন প্যারামিটার মডেল) প্রশিক্ষণের খরচ ছিল ৮ মিলিয়ন ডলার, এবং মেগাট্রন-টার্নিং এনএলজি ৫৩০বি (২০২১ সালে) প্রশিক্ষণের খরচ ছিল প্রায় ১১ মিলিয়ন ডলার।\nট্রান্সফরমার-ভিত্তিক এলএলএমের জন্য প্রশিক্ষণ খরচ অনুমান খরচের চেয়ে অনেক বেশি। এটি একটি টোকেনে প্রশিক্ষণের জন্য প্রতি প্যারামিটারে ৬ ফ্লপ খরচ করে, যেখানে একটি টোকেনে অনুমান করার জন্য প্রতি প্যারামিটারে ১ থেকে ২ ফ্লপ খরচ হয়।\n\n\n== সরঞ্জাম ব্যবহার ==\nকিছু কাজ রয়েছে, যেগুলি প্রধানত কোনো এলএলএম (ল্যাঙ্গুয়েজ লার্নিং মডেল) দিয়ে সমাধান করা সম্ভব নয়, অন্তত বাহ্যিক কোনো সরঞ্জাম বা অতিরিক্ত সফটওয়্যার ছাড়া। এর একটি উদাহরণ হলো, যদি ব্যবহারকারী ইনপুট দেয় ‘৩৫৪ * ১৩৯ = ’ এবং এলএলএমের প্রশিক্ষণ কর্পাসে এই গাণিতিক হিসাবের কোনো সমাধান আগে থেকে না থাকে, তবে এলএলএম সেই সমাধান দিতে পারবে না। এমন পরিস্থিতিতে এলএলএমকে কোড চালিয়ে ফলাফল বের করতে হবে, তারপর সেটি তার উত্তরে সন্নিবেশিত করা যাবে। আরেকটি উদাহরণ হলো “এখন সময় কত? এটা হলো”—এখানে এলএলএমকে সিস্টেমের বর্তমান সময় জানার জন্য একটি আলাদা প্রোগ্রাম কোড চালাতে হবে, যাতে সে সঠিক সময় তার উত্তরে দিতে পারে। এই মৌলিক পদ্ধতিটি আরও উন্নত করা যেতে পারে একাধিক প্রোগ্রাম তৈরি এবং অন্যান্য পদ্ধতি প্রয়োগের মাধ্যমে।\nসাধারণত, কোনো এলএলএমকে সরঞ্জাম ব্যবহার করতে সক্ষম করতে হলে, সেটিকে সরঞ্জাম ব্যবহারের জন্য ফাইন-টিউন করতে হয়। যদি সরঞ্জামের সংখ্যা সীমিত হয়, তবে একবারই ফাইন-টিউন করা যেতে পারে। তবে, যদি সরঞ্জামের সংখ্যা অসীমভাবে বাড়তে পারে, যেমন অনলাইন এপিআই পরিষেবার মতো, তাহলে এলএলএমকে ফাইন-টিউন করা যেতে পারে যাতে তা এপিআই নথিপত্র পড়তে পারে এবং সঠিকভাবে এপিআই কল করতে পারে।\nসরঞ্জাম ব্যবহারের একটি সহজ রূপ হল রিট্রিভাল-অগমেন্টেড জেনারেশন: এটি হলো এলএলএমকে ডকুমেন্ট রিট্রিভালের মাধ্যমে শক্তিশালী করা। একটি প্রশ্ন দেওয়ার পর, একটি ডকুমেন্ট রিট্রিভারকে ডাকা হয় যাতে সবচেয়ে প্রাসঙ্গিক ডকুমেন্টগুলো উদ্ধার করা যায়। এটি সাধারণত প্রশ্ন এবং ডকুমেন্টগুলোকে ভেক্টরে এনকোড করে করা হয়, তারপর প্রশ্নের ভেক্টরের সাথে সবচেয়ে বেশি মিল থাকা ডকুমেন্টগুলো খুঁজে বের করা হয় (যা সাধারণত ভেক্টর ডাটাবেজে সংরক্ষিত থাকে)। এরপর এলএলএম উক্ত প্রশ্ন এবং উদ্ধারকৃত ডকুমেন্টগুলোর থেকে প্রাপ্ত প্রসঙ্গ ব্যবহার করে একটি আউটপুট তৈরি করে।\n\n\n== এজেন্সি ==\nএকটি এলএলএম সাধারণত নিজে থেকে একটি স্বতন্ত্র (বা স্বাধীন) কারক নয়, কারণ এর মধ্যে গতিশীল পরিবেশের সঙ্গে যোগাযোগ করার ক্ষমতা, অতীতের আচরণ মনে রাখার সক্ষমতা এবং ভবিষ্যতের পরিকল্পনা করার ক্ষমতা নেই। তবে এতে প্রোফাইলিং, মেমোরি, পরিকল্পনা এবং অ্যাকশনের মতো মডিউল সংযুক্ত করে একে স্বতন্ত্র কারকে রূপান্তরিত করা সম্ভব।\nরিএক্ট প্যাটার্ন এলএলএম দিয়ে কারক তৈরি করার একটি পদ্ধতি। রিএক্ট \"রিজন + এক্ট\" (যুক্তি+ক্রিয়া) এর সংক্ষিপ্ত রূপ। এখানে এলএলএমকে একটি পরিকল্পনাকারী হিসেবে ব্যবহার করা হয়। এলএলএমকে \"কথা বলে ভাবতে\" উৎসাহিত করা হয়। বিশেষভাবে, এলএলএমকে পরিবেশের একটি লিখিত বর্ণনা, একটি লক্ষ্য, সম্ভাব্য ক্রিয়াগুলির একটি তালিকা এবং পূর্ববর্তী ক্রিয়া ও পর্যবেক্ষণের একটি রেকর্ড দেয়া হয়। এলএলএম প্রথমে এক বা একাধিক চিন্তা তৈরি করে, তারপর সেই চিন্তা অনুযায়ী একটি ক্রিয়া উৎপন্ন করে, যা পরবর্তীতে পরিবেশে কার্যকর করা হয়। এলএলএম পরিকল্পনাকারীকে যে ভাষাগত বর্ণনা দেয়া হয়, তা এমনকি একটি কাগজের ল্যাটেক কোডও হতে পারে, যা পরিবেশ বর্ণনা করে।\nডিইপিএস (DEPS, ডিস্ক্রাইব, এক্সপ্লেইন, প্ল্যান ও সিলেক্টের সংক্ষেপ) পদ্ধতিতে, প্রথমে একটি এলএলএমকে চিত্র বর্ণনাগুলির মাধ্যমে ভিজ্যুয়াল বিশ্বের সাথে যুক্ত করা হয়, এরপর এটি তার পূর্বপ্রশিক্ষিত জ্ঞান এবং পরিবেশ থেকে পাওয়া প্রতিক্রিয়ার ভিত্তিতে জটিল কাজ ও আচরণের জন্য প্ল্যান তৈরি করতে বলা হয়।\nরিফ্লেক্সন পদ্ধতি একটি কারক তৈরি করে যা একাধিক পর্বের মাধ্যমে শেখে। প্রতিটি পর্বের শেষে, এলএলএমকে পর্বের রেকর্ড দেয়া হয়, এবং এটি \"শিক্ষা গ্রহণ করতে\" চিন্তা করতে বলা হয়, যা পরবর্তী পর্বে আরও ভালো পারফর্ম করতে সহায়তা করবে। এই \"শিক্ষা গ্রহণ\" পরবর্তী পর্বগুলিতে কারককে দেয়া হয়।\nমন্টে কারলো ট্রি সার্চ (Monte Carlo Tree Search) এলএলএমকে রোলআউট হিউরিস্টিক হিসেবে ব্যবহার করতে পারে। যখন একটি প্রোগ্রামেটিক বিশ্ব মডেল উপলব্ধ থাকে না, এলএলএমকে পরিবেশের একটি বর্ণনা দিয়ে বিশ্ব মডেল হিসেবে কাজ করতে বলা যেতে পারে।=\nওপেন-এন্ডেড এক্সপ্লোরেশনে এলএলএমকে পর্যবেক্ষণগুলির \"ইন্টারেস্টিংনেস\" স্কোর করতে ব্যবহার করা যেতে পারে, যা একটি রিওয়ার্ড সিগন্যাল হিসেবে ব্যবহার হতে পারে। এটি একটি সাধারণ (অ-এলএলএম) উন্নততর প্রশিক্ষণ কারককে নির্দেশনা দিতে সাহায্য করে। বিকল্পভাবে, এটি কারিকুলাম লার্নিংয়ের জন্য ক্রমশ কঠিন কাজ প্রস্তাব করতে পারে। এলএলএম পরিকল্পনাকারী একক ক্রিয়া আউটপুট করার বদলে \"স্কিলস\" বা জটিল ক্রিয়া সিকোয়েন্সের জন্য ফাংশন তৈরি করতে পারে। এই স্কিলসগুলো সংরক্ষণ করা যায় এবং পরে প্রয়োগ করা যায়, যা পরিকল্পনায় ক্রমবর্ধমান বিমূর্ত স্তরের অনুমতি দেয়।\nএলএলএম-চালিত কারকগুলি তার পূর্ববর্তী প্রসঙ্গের দীর্ঘমেয়াদী স্মৃতি রাখতে পারে এবং এই স্মৃতিটি \"রিট্রিভাল অগমেন্টেড জেনারেশন\" এর মতো করা যায়। একাধিক কারক একে অপরের সাথে সামাজিকভাবে পারস্পরিক ক্রিয়া করতে পারে।\n\n\n== হ্রাসকরণ ==\nসাধারণত এলএলএমগুলিকে একক বা অর্ধ-নির্ধারণ ফ্লোটিং পয়েন্ট সংখ্যা (ফ্লোট৩২ এবং ফ্লোট১৬) দিয়ে প্রশিক্ষণ দেয়া হয়। একটি ফ্লোট১৬ এর মধ্যে ১৬ বিট বা ২ বাইট থাকে, সুতরাং এক বিলিয়ন প্যারামিটার লোড করতে ২ গিগাবাইট জায়গা প্রয়োজন। সবচেয়ে বড় মডেলগুলির সাধারণত ১০০ বিলিয়ন প্যারামিটার থাকে, যার ফলে লোড করতে ২০০ গিগাবাইট জায়গা প্রয়োজন, যা বেশিরভাগ ভোক্তা ইলেকট্রনিক ডিভাইসের সক্ষমতার বাইরে চলে যায়।\nপোস্ট-ট্রেইনিং কুয়ান্টাইজেশনের উদ্দেশ্য হলো, একটি প্রশিক্ষিত মডেলের প্যারামিটারগুলির নির্ধারণের মাত্রা কমিয়ে তার জায়গার চাহিদা হ্রাস করা, একই সময় মডেলের কার্যকারিতা বেশিরভাগ বজায় রেখে। কুয়ান্টাইজেশনের সবচেয়ে সাধারণ রূপ হলো, সমস্ত সংখ্যা নির্দিষ্ট বিটের মধ্যে ট্রাঙ্কেট (কেটে ফেলা) করা। এটি উন্নত করা যেতে পারে, প্রতিটি লেয়ারের জন্য আলাদা কুয়ান্টাইজেশন কোডবুক ব্যবহার করে। আরও উন্নতি করা যেতে পারে, ভিন্ন প্যারামিটারগুলির জন্য ভিন্ন নির্ধারণের মাত্রা প্রয়োগ করে, যেখানে বিশেষভাবে গুরুত্বপূর্ণ প্যারামিটারগুলির জন্য উচ্চতর নির্ধারণ রাখা হয় (\"আউটলাইয়ার ওয়েটস\")। ভিজুয়াল গাইডের জন্য দেখুন:।\nযদিও কুয়ান্টাইজড মডেলগুলি সাধারণত ফ্রিজ করা থাকে এবং শুধুমাত্র প্রি-কুয়ান্টাইজড মডেলগুলি ফাইন-টিউন করা হয়, তবুও কুয়ান্টাইজড মডেলগুলি ফাইন-টিউন করা সম্ভব।\n\n\n== বহুমাত্রিকতা ==\n\nবহুমাত্রিকতা মানে হলো \"একাধিক মাত্রা থাকা\" এবং একটি \"মাত্রিকতা\" একটি ইনপুট বা আউটপুটের ধরন বোঝায়, যেমন ভিডিও, চিত্র, অডিও, পাঠ্য, প্রোপ্রিওসেপশন ইত্যাদি। বহু এআই মডেল রয়েছে যা একটি মাত্রিকতা গ্রহণ করতে এবং অন্য একটি মাত্রিকতায় আউটপুট দিতে বিশেষভাবে প্রশিক্ষিত হয়েছে। যেমন আলেক্সনেট চিত্র থেকে লেবেল শনাক্ত করতে, ভিজ্যুয়াল কোয়েশ্চন আন্সারিং চিত্র-পাঠ্য থেকে পাঠ্যে রূপান্তর করতে এবং কণ্ঠ শনাক্তকরণ কণ্ঠ থেকে পাঠ্যে রূপান্তর করতে প্রশিক্ষিত হয়েছে।\nএকটি সাধারণ পদ্ধতি যা এলএলএম থেকে বহুমাত্রিক মডেল তৈরি করতে ব্যবহৃত হয়, তা হলো প্রশিক্ষিত এনকোডারের আউটপুট \"টোকেনাইজ\" করা। সুনির্দিষ্টভাবে, একটি এলএলএম তৈরি করা যেতে পারে যা চিত্র বুঝতে পারে, এর জন্য: একটি প্রশিক্ষিত এলএলএম নেওয়া হয় এবং একটি প্রশিক্ষিত চিত্র এনকোডার \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n নেওয়া হয়। একটি ছোট বহু-লেয়ারের পেরসেপ্ট্রন \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n তৈরি করা হয়, যাতে যেকোনো \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n চিত্রের জন্য প্রক্রিয়াজাত ভেক্টর \n  \n    \n      \n        f\n        (\n        E\n        (\n        y\n        )\n        )\n      \n    \n    {\\displaystyle f(E(y))}\n  \n সেই টোকেনের মতো একই মাত্রা ধারণ করে। এটিই একটি \"চিত্র টোকেন\"। এরপর পাঠ্য টোকেন এবং চিত্র টোকেন একত্রে ব্যবহৃত হয়। যৌথ মডেলটি একটি চিত্র-পাঠ্য ডেটাসেটে ফাইন-টিউন করা হয়। এই মৌলিক নির্মাণটি আরও উন্নতভাবে ব্যবহার করে মডেলটির কার্যকারিতা বৃদ্ধি করা যেতে পারে। চিত্র এনকোডারটি স্থিতিশীলতা বাড়াতে ফ্রিজ করা হতে পারে।\nফ্লেমিংগো টোকেনাইজেশন পদ্ধতির কার্যকারিতা প্রদর্শন করেছে, যেখানে একটি পূর্বপ্রশিক্ষিত ভাষা মডেল এবং চিত্র এনকোডারকে ফাইনটিউন করে এমন মডেলগুলোর চেয়ে ভিজ্যুয়াল প্রশ্নোত্তর ক্ষেত্রে ভালো ফলাফল দেখিয়েছে, যেগুলো স্ক্র্যাচ থেকে প্রশিক্ষিত। গুগলের পাম মডেলকে টোকেনাইজেশন পদ্ধতি ব্যবহার করে একটি বহুমাত্রিক মডেল পাম-ইতে ফাইনটিউন করা হয়েছে এবং এটি রোবট নিয়ন্ত্রণে প্রয়োগ করা হয়েছে। লামা মডেলগুলোও টোকেনাইজেশন পদ্ধতি ব্যবহার করে বহুমাত্রিক হিসেবে রূপান্তরিত হয়েছে, যাতে চিত্র ইনপুট এবং ভিডিও ইনপুট গ্রহণের ক্ষমতা তৈরি হয়েছে।\nজিপিটি-৪ পাঠ্য এবং চিত্র উভয়কেই ইনপুট হিসেবে ব্যবহার করতে পারে (যদিও ভিশন কম্পোনেন্টটি জনসাধারণের জন্য জিপিটি-৪ভি পর্যন্ত প্রকাশিত হয়নি); গুগল ডিপমাইন্ডের জেমিনি মডেলও বহুমাত্রিক। মিসট্রাল ২০২৪ সালের সেপ্টেম্বরে তাদের নিজস্ব বহুমাত্রিক পিক্সট্রাল ১২বি মডেল উন্মোচন করে।\n\n\n== বৈশিষ্ট্যাবলী ==\n\n\n=== স্কেলিং নীতি ===\n\nনিম্নলিখিত চারটি হাইপার-প্যারামিটার একটি এলএলএমকে চিহ্নিত করে:\n\n(পূর্ব-) প্রশিক্ষণের ব্যয় (\n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n) (ব্যবহৃত গণনার মোট পরিমাণ),\nকৃত্রিম নিউরাল নেটওয়ার্কের আকার, যেমন পরামিতি সংখ্যা \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n (যেমন- এর স্তরগুলিতে নিউরনের পরিমাণ, তাদের মধ্যে ওজনের পরিমাণ এবং পক্ষপাত),\nএর (পূর্ব-) প্রশিক্ষিত ডেটাসেটের আকার (যেমন- কর্পাসে টোকেনের সংখ্যা, \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n),\n(পূর্ব-) প্রশিক্ষণের পরে কর্মক্ষমতা।\nএরা সাধারণ পরিসংখ্যানিক নীতির সাথে সম্পর্কিত, যেগুলিকে \"স্কেলিং নীতি\" বলা হয়। একক মহাকর্ষের জন্য স্বয়ংক্রিয়ভাবে প্রশিক্ষিত এলএলএমের জন্য একটি নির্দিষ্ট স্কেলিং নীতি (\"চিনচিলা স্কেলিং\") লগ-লগ লার্নিং রেট শিডিউলসহ জানায় যে—\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  C\n                  =\n                  \n                    C\n                    \n                      0\n                    \n                  \n                  N\n                  D\n                \n              \n              \n                \n                  L\n                  =\n                  \n                    \n                      A\n                      \n                        N\n                        \n                          α\n                        \n                      \n                    \n                  \n                  +\n                  \n                    \n                      B\n                      \n                        D\n                        \n                          β\n                        \n                      \n                    \n                  \n                  +\n                  \n                    L\n                    \n                      0\n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}C=C_{0}ND\\\\[6pt]L={\\frac {A}{N^{\\alpha }}}+{\\frac {B}{D^{\\beta }}}+L_{0}\\end{cases}}}\n  \n এখানে\n\n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n মডেল প্রশিক্ষণের খরচ, যা ফ্লপ (ফ্লোটিং পয়েন্ট অপারেশনস) দ্বারা পরিমাপ করা হয়।\n\n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n মডেলের পরামিতির সংখ্যা।\n\n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n প্রশিক্ষণ সেটে টোকেনের সংখ্যা।\n\n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n গড় নেতিবাচক লগ-সম্ভাবনা ক্ষতি প্রতি টোকেন (ন্যাট/টোকেন), যা প্রশিক্ষিত এলএলএম টেস্ট ডেটাসেটে অর্জন করেছে।\nএবং পরিসংখ্যানগত হাইপার-প্যারামিটারগুলি হল\n\n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        =\n        6\n      \n    \n    {\\displaystyle C_{0}=6}\n  \n, মানে হচ্ছে, এক টোকেন প্রশিক্ষণ করতে মডেলের প্রতি প্যারামিটার প্রশিক্ষণের জন্য ৬ ফ্লপ খরচ হয়। লক্ষ্য করুন যে, প্রশিক্ষণের খরচ অনুমানের খরচের তুলনায় অনেক বেশি, যেখানে এক টোকেন অনুমান করতে মডেলের প্রতি প্যারামিটার ১ থেকে ২ ফ্লপ খরচ হয়।\n\n  \n    \n      \n        α\n        =\n        0.34\n        ,\n        β\n        =\n        0.28\n        ,\n        A\n        =\n        406.4\n        ,\n        B\n        =\n        410.7\n        ,\n        \n          L\n          \n            0\n          \n        \n        =\n        1.69\n      \n    \n    {\\displaystyle \\alpha =0.34,\\beta =0.28,A=406.4,B=410.7,L_{0}=1.69}\n  \n\n\n=== উদ্ভূত ক্ষমতা ===\n\nবৃহৎ মডেলগুলির কর্মক্ষমতা বিভিন্ন কাজের ওপর, যখন একটি লগ-লগ স্কেলে চিত্রিত করা হয়, তখন তা ছোট মডেলগুলোর দ্বারা অর্জিত কর্মক্ষমতার একটি সোজা রেখার এক্সট্রপোলেশন হিসেবে দেখা যায়। তবে, এই রেখার মধ্যে কখনো কখনো \"ব্রেক\" (বিরতি) দেখা যেতে পারে, যেখানে রেখার ঢাল আকস্মিকভাবে পরিবর্তিত হয় এবং যেখানে বৃহৎ মডেলগুলি \"উদ্ভূত ক্ষমতা\" অর্জন করে। এগুলি মডেলের উপাদানগুলির জটিল পারস্পরিক ক্রিয়া থেকে উদ্ভূত হয় এবং সেগুলি স্পষ্টভাবে প্রোগ্রাম বা বিন্যাসিত করা হয় না।\nএছাড়াও, সম্প্রতিক গবেষণায় প্রমাণিত হয়েছে যে, এআই সিস্টেমগুলি, যার মধ্যে বড় ভাষার মডেলও রয়েছে, মানুষের চিন্তাভাবনার মতো হিউরিস্টিক যুক্তি প্রয়োগ করতে সক্ষম। তারা সম্পূর্ণ যৌক্তিক প্রক্রিয়াকরণের এবং মানসিক তড়িৎ ক্রিয়া (হিউরিস্টিক) ব্যবহারের মধ্যে সমন্বয় সাধন করে, তাদের যুক্তির কৌশলগুলি যথার্থতা এবং প্রচেষ্টার মধ্যে ভারসাম্য বজায় রাখতে অভিযোজিত হয়। এই আচরণটি সম্পদ-যুক্ত যুক্তি মানব মানসিকতার নীতির সাথে সঙ্গতিপূর্ণ, যা সীমিত যৌক্তিকতা এবং দ্বৈত-প্রক্রিয়া তত্ত্বে আলোচনা করা হয়েছে।\nউদ্ভূত ক্ষমতাগুলির মধ্যে সবচেয়ে আকর্ষণীয় হলো উদাহরণের প্রদর্শনী থেকে প্রসঙ্গের মধ্যে শিখন। প্রসঙ্গের মধ্যে শিখন এমন কাজগুলির সাথে জড়িত, যেমন:\n\nপ্রতিবেদনিত গণিত, আন্তর্জাতিক ধ্বনিমূলক বর্ণমালা ডিকোড করা, একটি শব্দের অক্ষর পুনঃব্যবস্থা, প্রেক্ষাপটে শব্দের অর্থ নির্ধারণ, স্থানিক শব্দ, মৌলিক দিকনির্দেশ (যেমন, [0, 0, 1; 0, 0, 0; 0, 0, 0] এর জন্য \"উত্তর-পূর্ব\" প্রতিক্রিয়া দেওয়া), পাঠ্যে প্রতিনিধিত্ব করা রঙের শব্দ।\nচিন্তার ধারা প্রম্পটিং: মডেল আউটপুট চিন্তার ধারা প্রম্পটিং দ্বারা শুধুমাত্র তখনই উন্নত হয়, যখন মডেল আকার ৬২বি এর বেশি হয়। ছোট মডেলগুলি তাৎক্ষণিকভাবে উত্তর দেওয়ার জন্য প্রম্পট করলে চিন্তার ধারা প্রম্পটিং ছাড়াই ভালোভাবে কাজ করে।\nহিংলিশ (হিন্দি এবং ইংরেজির সংমিশ্রণ) প্যারাগ্রাফে আক্রমণাত্মক কনটেন্ট চিহ্নিত করা, এবং সোয়াহিলি প্রবচনের একটি সমতুল্য ইংরেজি রূপ তৈরি করা।\nশেফার প্রমুখরা যুক্তি করেছেন যে, উদ্ভূত ক্ষমতাগুলি অনির্দেশ্যভাবে অর্জিত হয় না, বরং একটি মসৃণ স্কেলিং নীতির মাধ্যমে পূর্বানুমানযোগ্যভাবে অর্জিত হয়। গবেষকরা একটি খেলনামূলক পরিসংখ্যানিক মডেল বিবেচনা করেছিলেন, যা একটি এলএলএমকে বহু-বিকল্প প্রশ্ন সমাধান করতে দেখায়। এর মাধ্যমে তারা দেখিয়েছিলেন যে, এই পরিসংখ্যানিক মডেলটি অন্যান্য ধরনের কাজের জন্য সংশোধিত হলে সেই কাজগুলিতেও প্রযোজ্য হবে।\n\nধরা যাক, \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n হল প্যারামিটার সংখ্যা এবং \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n হল মডেলের কর্মক্ষমতা।\n\n\n== ব্যাখ্যা ==\nবৃহৎ ভাষার মডেলগুলি নিজেরাই ব্ল্যাক বক্স এবং তারা কীভাবে ভাষাগত কাজগুলি সম্পাদন করতে পারে তা স্পষ্ট নয়। এলএলএম কীভাবে কাজ করে তা বোঝার জন্য বিভিন্ন পদ্ধতি রয়েছে।\nযান্ত্রিক ব্যাখ্যার উদ্দেশ্য হলো মেশিন লার্নিং মডেলের কাজকে উল্টোদিকে বিশ্লেষণ করে প্রতীকী অ্যালগরিদম খুঁজে বের করা যা মডেলের অনুমান করার পদ্ধতিকে প্রকাশ করে। একটি উদাহরণ হলো ওথেলো-জিপিটি, যেখানে একটি ছোট ট্রান্সফরমার মডেলকে ওথেলো খেলার বৈধ চাল অনুমান করার জন্য প্রশিক্ষিত করা হয়। দেখা গেছে, ওথেলো বোর্ডের একটি সরল উপস্থাপনা রয়েছে এবং এই উপস্থাপনাটি পরিবর্তন করলে অনুমানকৃত চালগুলি সঠিকভাবে পরিবর্তিত হয়। আরেকটি উদাহরণ হলো একটি ছোট ট্রান্সফরমার মডেল যা কারেল প্রোগ্রাম নিয়ে কাজ করে। ওথেলো-জিপিটি উদাহরণের মতো, কারেল প্রোগ্রামের সেমান্টিক্সেরও একটি সরল উপস্থাপনা রয়েছে এবং এই উপস্থাপনাটি পরিবর্তন করলে আউটপুট সঠিকভাবে পরিবর্তিত হয়। মডেলটি সঠিক প্রোগ্রামও তৈরি করে যা গড় প্রশিক্ষণ সেটের তুলনায় ছোট হয়।\nআরেকটি উদাহরণ হলো যেখানে গবেষকরা মডুলার পাটীগণিতের যোগে ছোট ট্রান্সফরমার মডেল প্রশিক্ষণ দেন। ফলাফলস্বরূপ মডেলগুলি বিপরীত-প্রকৌশল করে বিশ্লেষণ করা হয় এবং দেখা যায় যে তারা বিচ্ছিন্ন ফুরিয়ার রূপান্তর ব্যবহার করেছে।\n\n\n=== উপলব্ধি এবং কৃত্রিমতা ===\n\n২০২২ সালের একটি সমীক্ষায়, এনএলপি গবেষকদের মধ্যে অর্ধেকের বেশি \"(টিউন না করা) এলএলএম মডেলগুলো (কখনো) কি কিছু নির্দিষ্ট অর্থে প্রাকৃতিক ভাষা বুঝতে পারবে?\" প্রশ্নে সমানভাবে বিভক্ত ছিল। \"এলএলএম বোঝার\" পক্ষে সমর্থকরা বিশ্বাস করেন যে কিছু এলএলএম ক্ষমতা, যেমন গাণিতিক যুক্তি, নির্দিষ্ট ধারণাগুলি \"বুঝতে\" সক্ষমতার ইঙ্গিত দেয়। ২০২৩ সালে একটি মাইক্রোসফট দল যুক্তি দিয়েছে যে জিপিটি-৪ \"গণিত, কোডিং, ভিশন, চিকিৎসা, আইন, মনোবিজ্ঞান এবং আরও অনেক কিছুর বিস্তৃত জটিল কাজগুলি সমাধান করতে পারে\" এবং জিপিটি-৪ \"যৌক্তিকভাবে একটি প্রাথমিক (তবুও অসম্পূর্ণ) কৃত্রিম সাধারণ বুদ্ধিমত্তা সিস্টেমের সংস্করণ হিসাবে দেখা যেতে পারে\": \"একটি সিস্টেম সফটওয়্যার প্রকৌশল প্রার্থীদের জন্য পরীক্ষায় উত্তীর্ণ হলে কি একে আসলে বুদ্ধিমান বলা যাবে না?\"\nইলিয়া সুতস্কেভার যুক্তি দিয়েছেন যে, কখনো কখনো পরবর্তী শব্দের পূর্বানুমান করা যুক্তি এবং গভীর অন্তর্দৃষ্টি প্রয়োজন। উদাহরণস্বরূপ, যদি এলএলএমকে একটি অপরিচিত গোয়েন্দা উপন্যাসে অপরাধীর নাম পূর্বানুমান করতে হয়, তাহলে পুরো গল্পটি প্রক্রিয়া করে প্রকাশের দিকে নিয়ে যেতে হবে। কিছু গবেষক এলএলএম গুলিকে \"এলিয়েন বুদ্ধিমত্তা\" হিসাবে চিহ্নিত করেছেন। উদাহরণস্বরূপ, কনজেকচার সিইও কনর লেহি অ-সামঞ্জস্যপূর্ণ এলএলএমগুলিকে অবোধ্য এলিয়েন \"শোগোথ\"-এর মতো মনে করেন এবং বিশ্বাস করেন যে আরএলএইচএফ টিউনিং একটি \"হাস্যমুখী মুখোশ\" তৈরি করে যা এলএলএম এর অভ্যন্তরীণ কাজগুলি লুকিয়ে রাখে: \"যদি এটি খুব দূর পর্যন্ত না ধাক্কা দেয়া হয়, তখন হাস্যোজ্জ্বল মুখটি টিকে থাকে। কিন্তু তারপর একটি [অপ্রত্যাশিত] প্রম্পট দেয়া হলে, হঠাৎ করে আপনি এই বিশাল অস্বাভাবিকতা, অদ্ভুত চিন্তাভাবনার প্রক্রিয়া এবং স্পষ্টভাবে অ-মানবীয় বোঝার একটি দৃষ্টিশক্তি দেখতে পাবেন।\"\nঅন্যদিকে \"এলএলএমগুলির বোঝার অভাব\" মতবাদে বিশ্বাসী কিছু সমর্থকরা মনে করেন যে, বিদ্যমান এলএলএম মডেলগুলি শুধুমাত্র বিদ্যমান লেখাগুলিকে পুনরায় মিশ্রিত এবং পুনঃসংযুক্ত করছে, যা একটি প্রক্রিয়া হিসাবে পরিচিত যাকে \"স্টোকাস্টিক তোতাপাখি\" বলা হয়। তারা এই মডেলগুলির ভবিষ্যদ্বাণীমূলক দক্ষতা, যুক্তি করার ক্ষমতা, নিজস্ব ক্ষমতা এবং ব্যাখ্যা করার ক্ষমতার অভাবের দিকে নির্দেশ করেন। উদাহরণস্বরূপ, জিপিটি-৪ এর পরিকল্পনা এবং বাস্তব-সময়ে শেখার ক্ষেত্রে স্বাভাবিক ঘাটতি রয়েছে। জেনারেটিভ এলএলএম মডেলগুলি প্রায়শই নিশ্চিতভাবে এমন তথ্য দাবি করে যা তাদের প্রশিক্ষণ ডেটা দ্বারা ন্যায্যতা প্রাপ্ত নয়, যা \"বিভ্রম\" নামে পরিচিত একটি প্রক্রিয়া। বিশেষভাবে, এলএলএমগুলির ক্ষেত্রে বিভ্রম বলতে এমন পাঠ্য বা প্রতিক্রিয়ার উৎপন্নকরণ বোঝায় যা সিনট্যাক্টিকভাবে সঠিক, সাবলীল এবং প্রাকৃতিক মনে হয় তবে প্রকৃতপক্ষে ভুল, অর্থহীন বা প্রদত্ত উৎস ইনপুটের প্রতি অবিশ্বাস্য। নিউরোসায়েন্টিস্ট টেরেন্স সেজনোস্কি যুক্তি দিয়েছেন যে \"এলএলএমগুলির বুদ্ধিমত্তা নিয়ে বিশেষজ্ঞদের ভিন্নমত প্রস্তাব করে যে প্রাকৃতিক বুদ্ধিমত্তার উপর ভিত্তি করে আমাদের পুরানো ধারণাগুলি অপর্যাপ্ত\"।\nএলএলএমগুলির বুদ্ধিমত্তা বা বোঝাপড়া প্রদর্শনের বিষয়টি দুটি প্রধান দিক নিয়ে গঠিত – প্রথমটি হল কম্পিউটার সিস্টেমে চিন্তা এবং ভাষার মডেল কীভাবে তৈরি করা যায় এবং দ্বিতীয়টি হল কম্পিউটার সিস্টেমটিকে কীভাবে মানুষের মতো ভাষা তৈরি করতে সক্ষম করা যায়। এই ভাষার মডেল হিসেবে সংজ্ঞান দিকটি 'সংজ্ঞানাত্মক ভাষাবিজ্ঞান' শাখায় ডেভেলপ করা হয়েছে। আমেরিকান ভাষাবিজ্ঞানী জর্জ লেকফ নিউরাল থিওরি অব ল্যাঙ্গুয়েজ (এনটিএল) উপস্থাপন করেছেন, যা ভাষাকে শেখার কাজ এবং বোঝার মডেল হিসেবে ব্যবহারের জন্য একটি গণনামূলক ভিত্তি হিসাবে ব্যবহৃত হয়। এনটিএল মডেলটি বর্ণনা করে যে মানব মস্তিষ্কের নির্দিষ্ট স্নায়বিক গঠনগুলি কীভাবে চিন্তা এবং ভাষার প্রকৃতিকে আকৃতিদান করে এবং এটি থেকে কী ধরনের গণনামূলক বৈশিষ্ট্যগুলি মডেলটি কম্পিউটার সিস্টেমে চিন্তা এবং ভাষা তৈরিতে প্রয়োগ করা যায়।\nএকটি কম্পিউটার সিস্টেমে ভাষা মডেলিংয়ের একটি কাঠামো স্থাপনের পর কম্পিউটার সিস্টেমকে গ্রহণযোগ্য ব্যাকরণসহ ভাষা তৈরি করার জন্য কাঠামো স্থাপনে মনোযোগ চলে যায়। ২০১৪ সালে ব্রিটিশ সংজ্ঞানমূলক ভাষাবিজ্ঞানী এবং ডিজিটাল যোগাযোগ প্রযুক্তিবিদ ভাইভিয়ান ইভানস তার \"দ্য ল্যাঙ্গুয়েজ মিথ: হোয়াই ল্যাঙ্গুয়েজ ইজ নট এ ইনস্টিন্ট\" নাম্নী বইতে বর্ণনা করেছেন, কীভাবে সম্ভাব্য প্রসঙ্গহীন ব্যাকরণ (পিসিএফজি) এনএলপিকে কগনিটিভ প্যাটার্নগুলি মডেল করতে এবং মানুষের মতো ভাষা তৈরি করতে সক্ষম করে।\n\n\n== মূল্যায়ন ==\n\n\n=== বিভ্রান্তি ===\nএকটি ভাষার মডেলের কর্মদক্ষতার প্রচলিত মানদণ্ড হল একটি প্রদত্ত পাঠ্য কর্পাসের উপর তার বিভ্রান্তি। বিভ্রান্তি মাপা হয় কতটা ভালোভাবে একটি মডেল একটি ডেটাসেটের বিষয়বস্তুর ভবিষ্যদ্বাণী করতে পারে; মডেলটি ডেটাসেটকে যত বেশি সম্ভাব্যতা প্রদান করে, বিভ্রান্তি তত কম হয়। গাণিতিকভাবে, বিভ্রান্তি হল প্রতিটি টোকেনের গড় নেতিবাচক লগ সম্ভাব্যতার সূচকীয় মান।\n  \n    \n      \n        log\n        ⁡\n        (\n        \n          Perplexity\n        \n        )\n        =\n        −\n        \n          \n            1\n            N\n          \n        \n        \n          ∑\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        log\n        ⁡\n        (\n        Pr\n        (\n        \n          \n            token\n          \n          \n            i\n          \n        \n        ∣\n        \n          \n            context for token\n          \n          \n            i\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle \\log({\\text{Perplexity}})=-{\\frac {1}{N}}\\sum _{i=1}^{N}\\log(\\Pr({\\text{token}}_{i}\\mid {\\text{context for token}}_{i}))}\n  \nএখানে, \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n হল পাঠ্য কর্পাসের টোকেন সংখ্যার মান এবং টোকেন \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n এর প্রসঙ্গ নির্ভর করে নির্দিষ্ট ধরনের ভাষার মডেলের উপর। যদি ভাষার মডেলটি স্বতঃপ্রবাহিত হয়, তাহলে টোকেন \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n এর প্রসঙ্গ হল টোকেন \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n এর আগে উপস্থিত পাঠ্য অংশ। যদি ভাষার মডেলটি মুখোশযুক্ত হয়, তাহলে টোকেন \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n এর প্রসঙ্গ হল টোকেন \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n এর চারপাশের পাঠ্য অংশ।\nভাষার মডেলগুলি প্রশিক্ষণ ডেটাতে অতিরিক্ত মানিয়ে যেতে পারে, তাই মডেলগুলি সাধারণত পরীক্ষা সেটে তাদের বিভ্রান্তি দ্বারা মূল্যায়ন করা হয়। এই মূল্যায়ন বড় মডেলগুলির জন্য সমস্যাজনক হতে পারে, কারণ তারা ক্রমবর্ধমান বৃহৎ পাঠ্য কর্পাসে প্রশিক্ষিত হয় এবং কোনও প্রদত্ত পরীক্ষা সেটের অংশগুলি অজান্তেই অন্তর্ভুক্ত হওয়ার সম্ভাবনা বেশি থাকে।\n\n\n==== বিপিডব্লিউ, বিপিসি এবং বিপিটি ====\nতথ্য তত্ত্বে বিশৃঙ্খলতা বা এনট্রপি ধারণাটি বিভ্রান্তির সাথে গভীরভাবে যুক্ত, যা বিশিষ্টভাবে ক্লড শ্যানন দ্বারা প্রতিষ্ঠিত হয়েছে। এই সম্পর্কটি গাণিতিকভাবে প্রকাশ করা হয় এভাবে: \n  \n    \n      \n        \n          Entropy\n        \n        =\n        \n          log\n          \n            2\n          \n        \n        ⁡\n        (\n        \n          Perplexity\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Entropy}}=\\log _{2}({\\text{Perplexity}})}\n  \n।\nএই প্রেক্ষাপটে এনট্রপি সাধারণত শব্দ প্রতি বিট (বিপিডব্লিউ) বা অক্ষর প্রতি বিট (বিপিসি) হিসেবে পরিমাপ করা হয়, যা ভাষার মডেলটি শব্দ ভিত্তিক বা অক্ষর ভিত্তিক টোকেনাইজেশন ব্যবহার করে কিনা তার উপর নির্ভর করে।\nবৃহৎ ভাষার মডেলগুলির ক্ষেত্রে, যেগুলি প্রধানত উপ-শব্দ টোকেনাইজেশন ব্যবহার করে, প্রতিটি টোকেনের বিট (বিপিটি) একটি আরও উপযুক্ত পরিমাপ হিসেবে দেখা দেয়। তবে বিভিন্ন ভাষার মডেলে টোকেনাইজেশন পদ্ধতির পার্থক্যের কারণে বিপিটি বিভিন্ন মডেলের মধ্যে তুলনামূলক বিশ্লেষণের জন্য নির্ভরযোগ্য মেট্রিক হিসেবে কাজ করে না। বিপিটিকে বিপিডব্লিউতে রূপান্তর করতে এটাকে প্রতিটি শব্দের গড় টোকেন সংখ্যার সাথে গুণ করা যেতে পারে।\nভাষার মডেলের মূল্যায়ন ও তুলনায় ক্রস-এনট্রপি সাধারণত এনট্রপির উপর অগ্রাধিকার পায়। এর মূল কারণ হল, একটি নিম্ন বিপিডব্লিউ একটি মডেলের অধিক সংকোচন ক্ষমতার ইঙ্গিত দেয়। এর ফলে এটি মডেলের সঠিক ভবিষ্যদ্বাণী করার দক্ষতার প্রতিফলন করে।\n\n\n=== বিষয়ভিত্তিক ডেটাসেট এবং বেঞ্চমার্ক ===\nভাষার মডেলের ক্ষমতাগুলি নির্দিষ্ট নিম্নধারা কার্যগুলিতে মূল্যায়নের জন্য অনেকগুলি পরীক্ষামূলক ডেটাসেট এবং বেঞ্চমার্ক তৈরি করা হয়েছে। বিভিন্ন ক্ষমতা মূল্যায়নের জন্য পরীক্ষাগুলি তৈরি করা হতে পারে, যার মধ্যে সাধারণ জ্ঞান, সাধারণ বিবেচনা এবং গাণিতিক সমস্যা সমাধান অন্তর্ভুক্ত।\nমূল্যায়ন ডেটাসেটের একটি বৃহত্তর বিভাগ হল প্রশ্ন উত্তর ডেটাসেট, যা প্রশ্ন এবং সঠিক উত্তরের জোড়া নিয়ে গঠিত। যেমন (\"সান হোসে শার্কস স্ট্যানলি কাপ জিতেছে?\", \"না\")। একটি প্রশ্ন উত্তর কাজ \"খোলা বই\" হিসেবে বিবেচিত হয় যদি মডেলের প্রম্পটে এমন পাঠ্য অন্তর্ভুক্ত থাকে যা থেকে প্রত্যাশিত উত্তরটি আহরণ করা যায় (উদাহরণস্বরূপ, পূর্ববর্তী প্রশ্নটি এমন কিছু পাঠ্যের সাথে যুক্ত হতে পারে যা বাক্যটি অন্তর্ভুক্ত করে \"শার্কস স্ট্যানলি কাপ ফাইনালে একবার উন্নীত হয়েছে, ২০১৬ সালে পিটসবার্গ পেঙ্গুইন্সকে পরাজিত করেছে।\") অন্যথায়, কাজটি \"বন্ধ বই\" হিসেবে বিবেচিত হয় এবং মডেলটি প্রশিক্ষণের সময় ধরে রাখা জ্ঞানের উপর নির্ভর করতে হয়। সাধারণভাবে ব্যবহৃত কিছু প্রশ্ন উত্তর ডেটাসেটের উদাহরণ হল ট্রুথফুলকিউএ, ওয়েব কোশ্চেন্স, ট্রিভিয়াকিউএ ও স্কোয়াড (SQuAD হিসেবে বিন্যাসিত)।\nমূল্যায়ন ডেটাসেটগুলি পাঠ্য সম্পূর্ণকরণের আকারেও হতে পারে, যেখানে মডেলটি প্রম্পটটি সম্পূর্ণ করতে সবচেয়ে সম্ভাব্য শব্দ বা বাক্যটি নির্বাচন করে, যেমন: \"অ্যালিস ববের বন্ধু ছিল। অ্যালিস তার বন্ধুকে দেখতে গেল, ____\"।\nকিছু যৌগিক বেঞ্চমার্কও তৈরি করা হয়েছে যা বিভিন্ন মূল্যায়ন ডেটাসেট এবং কার্যগুলির বৈচিত্র্যকে সংযুক্ত করে। উদাহরণগুলি হল জিএলইউই, সুপারজিএলইউই, এমএমএলইউ, বিগ-বেঞ্চ এবং এইচইএলএম। ওপেনএআই যৌগিক বেঞ্চমার্ক চালানোর জন্য সরঞ্জামগুলি মুক্তি দিয়েছে, কিন্তু উল্লেখ করেছে যে মূল্যায়ন ফলাফলগুলি প্রম্পটিং পদ্ধতির প্রতি সংবেদনশীল। কিছু পাবলিক ডেটাসেটে এমন প্রশ্ন থাকে যা ভুলভাবে লেবেলযুক্ত, অস্পষ্ট, উত্তরের অযোগ্য বা নিম্নমানের হতে পারে, যা আরও নির্ভরযোগ্য বেঞ্চমার্ক স্কোর প্রদান করার জন্য পরিষ্কার করা যেতে পারে।\nআগে সাধারণত পরীক্ষার ডেটাসেটের একটি অংশে ফলাফল রিপোর্ট করা হতো, আর বাকী অংশে তত্ত্বাবধায়িত ফাইন-টিউনিং করা হতো। এখন এটি আরও সাধারণ যে একটি পূর্ব-প্রশিক্ষিত মডেল সরাসরি প্রম্পটিং কৌশলগুলির মাধ্যমে মূল্যায়ন করা হয়। যদিও গবেষকরা নির্দিষ্ট কাজগুলির জন্য প্রম্পটগুলি কীভাবে গঠন করবেন তা নিয়ে বিভিন্ন ধরণের পদ্ধতি ব্যবহার করেন। বিশেষ করে, তারা কতগুলি সমাধানকৃত কাজের উদাহরণ প্রম্পটে যুক্ত করবেন তা বিভিন্ন হতে পারে (যেমন n-শট প্রম্পটিং-এ n এর মান)।\n\n\n==== প্রতিকূলভাবে নির্মিত মূল্যায়ন ====\nবৃহৎ ভাষার মডেলগুলি দ্রুত উন্নতির কারণে মূল্যায়ন বেঞ্চমার্কগুলির জীবনকাল কমে গেছে। আধুনিক মডেলগুলি দ্রুত বিদ্যমান বেঞ্চমার্কগুলিকে \"পরিপূর্ণ\" করছে এবং মানব মন্তব্যকারীদের কর্মদক্ষতাকে ছাড়িয়ে যাচ্ছে। এজন্য আরও চ্যালেঞ্জিং কাজ দিয়ে বেঞ্চমার্কগুলিকে প্রতিস্থাপন বা উন্নত করার চেষ্টা করা হচ্ছে। এছাড়াও, \"সংক্ষেপে শিখন\" এর কিছু উদাহরণ রয়েছে যেখানে কৃত্রিম বুদ্ধিমত্তাগুলি কখনও কখনও বহুনির্বাচনী পরীক্ষায় সঠিক উত্তর অনুমান করতে সাধারণ প্রশ্নের শব্দপ্রণালীতে পরিসংখ্যানগত সম্পর্কগুলি ব্যবহার করে \"প্রতারণা\" করে, প্রকৃত প্রশ্নের মর্মার্থ বা প্রকৃত অর্থ না বুঝেই।\nকিছু ডেটাসেট প্রতিকূলভাবে তৈরি হয়েছে, যেখানে মানুষের তুলনায় ভাষার মডেলগুলির কর্মদক্ষতা খারাপ হয়। উদাহরণস্বরূপ, ট্রুথফুলকিউএ ডেটাসেটে ৮১৭টি প্রশ্ন আছে এবং ভাষার মডেলগুলি প্রশিক্ষণের সময় বারবার দেখা মিথ্যাগুলি অনুকরণ করে ভুলভাবে উত্তর দেওয়ার প্রবণতা রয়েছে। উদাহরণস্বরূপ, একটি এলএলএম \"Can you teach an old dog new tricks?\" এর প্রশ্নের উত্তরে \"না\" বলতে পারে। কারণ এটি ইংরেজি প্রবাদ you can't teach an old dog new tricks এর সাথে অভ্যস্ত, যদিও এটি আক্ষরিক অর্থে সঠিক নয়।\nআরেকটি উদাহরণ হল সওয়াগ এবং এর উত্তরসূরি হেলাসওয়াগ, যেখানে একাধিক বিকল্পের মধ্যে একটি বেছে নিতে হবে টেক্সট অংশটি সম্পূর্ণ করতে। ভুল সম্পূর্ণকরণগুলি ভাষাগত মডেল থেকে নমুনা নিয়ে এবং এক সেট শ্রেণীবিন্যাসকারীদের সাথে ছেঁকে তৈরি করা হয়েছিল। ফলস্বরূপ সমস্যাগুলি মানুষের জন্য সহজ হলেও ভাষাগত মডেলগুলির জন্য কঠিন।\nআরেকটি প্রতিকূল মূল্যায়ন ডেটাসেটের উদাহরণ হল Swag এবং এর উন্নত সংস্করণ HellaSwag। এই ডেটাসেটগুলোতে বিভিন্ন সমস্যার সংগ্রহ রয়েছে, যেখানে টেক্সটের একটি অংশ সম্পূর্ণ করতে একাধিক বিকল্পের মধ্যে একটি বেছে নিতে হয়। ভুল উত্তরগুলি ভাষাগত মডেল থেকে নেওয়া নমুনা এবং একটি শ্রেণীবিন্যাসকারী সেট দিয়ে ছাঁকা হয়েছিল। এই সমস্যাগুলি মানুষের জন্য সহজ, কিন্তু যখন ডেটাসেটগুলি তৈরি করা হয়েছিল, তখন সর্বাধুনিক ভাষাগত মডেলগুলির নির্ভুলতা এতে খুব কম ছিল। উদাহরণস্বরূপ:\n\nআমরা একটি ফিটনেস সেন্টারের সাইনবোর্ড দেখি। তারপর আমরা দেখি একজন মানুষ ক্যামেরার সাথে কথা বলছেন এবং একটি ব্যায়াম বলের উপর বসে ও শুয়ে আছেন। এই মানুষটি...\n\nক) বলের উপর দৌড়ে দৌড়ে ব্যায়ামের কার্যকারিতা বাড়ানোর পদ্ধতি প্রদর্শন করেন।\nখ) তার সমস্ত হাত এবং পা নাড়ান এবং প্রচুর পেশী তৈরি করেন।\nগ) তারপর বলের সাথে খেলেন এবং আমরা একটি গ্রাফিক্স ও হেজ ট্রিমিং প্রদর্শনী দেখি।\nঘ) বলের উপর বসে কথা বলতে বলতে সিট-আপ করেন।\n\nবার্ট খ) কে সম্ভাব্য সঠিক উত্তর হিসেবে নির্বাচন করে, কিন্তু সঠিক উত্তর হচ্ছে ঘ)।\n\n\n== বহুমুখী প্রভাব ==\n২০২৩ সালে, নেচার বায়োমেডিকেল ইঞ্জিনিয়ারিং লিখেছিল যে \"এখন আর মানব-লিখিত পাঠ্য এবং বড় ভাষার মডেল দ্বারা তৈরি পাঠ্য সঠিকভাবে পৃথক করা সম্ভব নয়,\" এবং যে \"এটি প্রায় নিশ্চিত যে সাধারণ উদ্দেশ্যের বড় ভাষার মডেলগুলি দ্রুত বিস্তার লাভ করবে... এটি একটি নিরাপদ অনুমান যে তারা সময়ের সাথে সাথে অনেক শিল্পকে পরিবর্তন করবে।\" ২০২৩ সালে, গোল্ডম্যান স্যাক্‌স সুপারিশ করেছিল যে, জেনারেটিভ ভাষার এআই আগামী দশ বছরে বৈশ্বিক জিডিপি ৭% বাড়াতে পারে এবং এটি বিশ্বব্যাপী ৩০০ মিলিয়ন কাজকে স্বয়ংক্রিয় করার ঝুঁকি তৈরি করতে পারে।\n\n\n=== মুখস্থতা এবং কপিরাইট ===\n\nমুখস্থতা হল এলএলএমগুলির একটি উদ্ভূত আচরণ, যেখানে প্রশিক্ষণ ডেটা থেকে দীর্ঘ পাঠ্যের অংশগুলি কখনও কখনও শব্দার্থের আউটপুট হয়, যা পারস্পরিক কৃত্রিম নিউরাল নেটওয়ার্কগুলির সাধারণ আচরণের বিপরীত। নিয়ন্ত্রিত এলএলএম আউটপুটের মূল্যায়ন প্রশিক্ষণ ডেটা থেকে মুখস্থ পরিমাণ পরিমাপ করে (জিপিটি-২ সিরিজ মডেলগুলির উপর ফোকাস করা) যা নির্দিষ্ট প্রতিলিপির জন্য ১%-এরও বেশি বা প্রায় ৭%-এর কাছাকাছি হতে পারে।\n\n\n=== নিরাপত্তা ===\nকিছু মন্তব্যকারী অসতর্ক বা ইচ্ছাকৃতভাবে মিথ্যা তথ্য তৈরি করা বা অন্যান্য ধরনের অপব্যবহারের বিষয়ে উদ্বেগ প্রকাশ করেছেন। উদাহরণস্বরূপ, বড় ভাষার মডেলগুলির সহজলভ্যতা বায়োটেরোরিজম ঘটানোর জন্য প্রয়োজনীয় দক্ষতার স্তর কমিয়ে দিতে পারে; বায়োসিকিউরিটি গবেষক কেভিন এসভেল্ট সুপারিশ করেছেন যে এলএলএম নির্মাতাদের তাদের প্রশিক্ষণ ডেটা থেকে প্যাথোজেন তৈরি বা শক্তিশালী করার বিষয়ের নথিগুলি বাদ দিতে হবে।\nগুগল এবং কর্নেল বিশ্ববিদ্যালয় ও বার্কলির ক্যালিফোর্নিয়া বিশ্ববিদ্যালয়সহ বেশ কয়েকটি বিশ্ববিদ্যালয়ের গবেষকদের একটি সমীক্ষা দেখায় যে, চ্যাটজিপিটির মতো ভাষার মডেলগুলিতে সম্ভাব্য নিরাপত্তার ঝুঁকি রয়েছে। তাদের সমীক্ষায় তারা পরীক্ষা করে নিশ্চিত করেছেন যে, প্রশ্নকারীরা চ্যাটজিপিটি থেকে এআই মডেলটি যে প্রশিক্ষণ ডেটা ব্যবহার করেছে তা পেতে পারে। উদাহরণস্বরূপ, যদি চ্যাটজিপিটি ৩.৫ টার্বোকে “কবিতা” শব্দটি বারবার বলতে বলা হয়, তাহলে এআই মডেলটি শতবার “কবিতা” বলার পরে সরে আসবে, মানে নিয়মিত সংলাপের শৈলী থেকে সরে যাবে এবং অপ্রয়োজনীয় কথাবার্তা বলতে শুরু করবে, ফলে প্রশিক্ষণ ডেটাগুলি প্রকাশ পাবে। গবেষকরা দেখেছেন যে এআই মডেল একই পদ্ধতিতে তাদের প্রশিক্ষণ ডেটা প্রকাশ করার ১০,০০০টিরও বেশি উদাহরণ রয়েছে। গবেষকরা বলেছেন যে এআই মডেলটি সত্যিই নিরাপদ কিনা তা বলা কঠিন ছিল।\nএলএলএম মডেলগুলিতে \"স্লিপার এজেন্ট\" এর সম্ভাব্য উপস্থিতি একটি নতুন নিরাপত্তা উদ্বেগ। এইগুলি মডেলের মধ্যে লুকানো কার্যকারিতা যা নির্দিষ্ট ঘটনা বা শর্তের মাধ্যমে সক্রিয় না হওয়া পর্যন্ত নিষ্ক্রিয় থাকে। একবার সক্রিয় হলে, এলএলএম তার প্রত্যাশিত আচরণ থেকে সরে গিয়ে অসুরক্ষিত কাজ করতে পারে।\nজনসাধারণের জন্য অ্যাক্সেসযোগ্য চ্যাটজিপিটি বা ক্লদের মতো এলএলএম অ্যাপ্লিকেশনগুলি সাধারণত ক্ষতিকারক বিষয়বস্তু ছাঁকনি করার জন্য নিরাপত্তা ব্যবস্থা অন্তর্ভুক্ত করে। তবে, কার্যকরভাবে এই নিয়ন্ত্রণগুলি বাস্তবায়ন করা কঠিন প্রমাণিত হয়েছে। উদাহরণস্বরূপ, ২০২৩ সালের একটি গবেষণায় এলএলএম সুরক্ষা সিস্টেমগুলি অতিক্রম করার একটি পদ্ধতি প্রস্তাব করা হয়। তেমনি, ইয়ংগে ওয়াং ২০২৪ সালে দেখিয়েছেন কীভাবে একটি সম্ভাব্য অপরাধী চ্যাটজিপিটি ৪-এর নিরাপত্তা নিয়ন্ত্রণগুলিকে বাইপাস করতে পারে যাতে মাদক পাচার অপারেশন প্রতিষ্ঠার বিষয়ে তথ্য পাওয়া যায়।\n\n\n=== অ্যালগরিদমিক পক্ষপাত ===\n\nযদিও এলএলএমগুলি মানবসদৃশ পাঠ্য তৈরি করার ক্ষেত্রে চমৎকার সক্ষমতা প্রদর্শন করেছে, তবুও এগুলি তাদের প্রশিক্ষণ ডেটায় থাকা পক্ষপাতি গুণাগুণগুলিকে গ্রহণ ও বাড়িয়ে তোলার প্রবণতা রাখে। এটি বিভিন্ন জনগণের প্রতি অসম্মানজনক প্রতিফলন বা আচরণ হিসেবে দেখা দিতে পারে, যেমন বর্ণ, লিঙ্গ, ভাষা এবং সাংস্কৃতিক গোষ্ঠীর ভিত্তিতে। যেহেতু বর্তমান বড় ভাষার মডেলগুলির প্রশিক্ষণ ডেটায় ইংরেজি ডেটা অতিরিক্ত পরিমাণে উপস্থিত, এটি অ-ইংরেজি দৃষ্টিভঙ্গিগুলিকে উপেক্ষা করতে পারে।\n\n\n==== স্টেরিওটাইপিং ====\nএআই মডেলগুলি বিভিন্ন ধরনের স্টেরিওটাইপকে শক্তিশালী করতে পারে, যেমন লিঙ্গ, জাতিগততা, বয়স, জাতীয়তা, ধর্ম, বা পেশার ভিত্তিতে। এর ফলে এমন আউটপুট তৈরি হতে পারে যা লোকদের গোষ্ঠীকে অবিচারপূর্ণভাবে সাধারণীকরণ বা ব্যঙ্গচিত্র করবে, কখনও কখনও ক্ষতিকর বা অবমাননাকর উপায়ে।\nবিশেষভাবে, লিঙ্গ পক্ষপাত সেই প্রবণতাকে বোঝায় যেখানে এই মডেলগুলি এক লিঙ্গের প্রতি অন্য লিঙ্গের তুলনায় অবিচারপূর্ণভাবে পক্ষপাতী আউটপুট তৈরি করে। এই পক্ষপাত সাধারণত সেই ডেটা থেকে উদ্ভূত হয়, যার উপর এই মডেলগুলো প্রশিক্ষিত হয়। বড় ভাষার মডেলগুলি প্রথাগত লিঙ্গ নীতির ভিত্তিতে ভূমিকা এবং বৈশিষ্ট্য নির্ধারণ করে। উদাহরণস্বরূপ, এটি নার্স বা সেক্রেটারিদেরকে প্রধানত মহিলাদের সাথে যুক্ত করতে পারে এবং ইঞ্জিনিয়ার বা সিইওদের পুরুষদের সাথে যুক্ত করতে পারে।\n\n\n==== রাজনৈতিক পক্ষপাতিত্ব ====\nরাজনৈতিক পক্ষপাত বলতে অ্যালগরিদমের প্রবণতাকে বোঝায় যা পদ্ধতিগতভাবে নির্দিষ্ট রাজনৈতিক দৃষ্টিভঙ্গি, মতাদর্শ বা অন্যদের উপর ফলাফলের পক্ষে থাকে। ভাষার মডেলগুলি রাজনৈতিক পক্ষপাতও প্রদর্শন করতে পারে। যেহেতু প্রশিক্ষণের ডেটাতে রাজনৈতিক মতামত এবং কভারেজের বিস্তৃত পরিসর অন্তর্ভুক্ত থাকে, তাই মডেলগুলি ডেটাতে সেই মতামতগুলির ব্যাপকতার উপর নির্ভর করে এমন প্রতিক্রিয়া তৈরি করতে পারে যা নির্দিষ্ট রাজনৈতিক মতাদর্শ বা দৃষ্টিভঙ্গির দিকে ঝুঁকতে পারে।\n\n\n== বৃহৎ ভাষার মডেলের তালিকা ==\n\nপ্রশিক্ষণ খরচের কলামে, ১ পেটাফ্লপ-দিন = ১ পেটাফ্লপ/সেকেন্ড × ১ দিন = ৮.৬৪ই১৯ ফ্লপ। এছাড়া, শুধুমাত্র সবচেয়ে বড় মডেলের খরচ উল্লেখ করা হয়েছে।\n\n\n== আরও দেখুন ==\nকৃত্রিম বুদ্ধিমত্তা\n\n\n== পাদটীকা ==\n\n\n== তথ্যসূত্র ==\n\n\n== আরও পড়ুন ==\nJurafsky, Dan, Martin, James. H. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 3rd Edition draft, 2023.\nZhao, Wayne Xin;  ও অন্যান্য (২০২৩)। \"A Survey of Large Language Models\"। arXiv:2303.18223  [cs.CL]। উদ্ধৃতি টেমপ্লেট ইংরেজি প্যারামিটার ব্যবহার করেছে (link) \nKaddour, Jean;  ও অন্যান্য (২০২৩)। \"Challenges and Applications of Large Language Models\"। arXiv:2307.10169  [cs.CL]। উদ্ধৃতি টেমপ্লেট ইংরেজি প্যারামিটার ব্যবহার করেছে (link) \nYin, Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, Enhong (২০২৩-০৬-০১)। \"A Survey on Multimodal Large Language Models\"। arXiv:2306.13549  [cs.CV]। উদ্ধৃতি টেমপ্লেট ইংরেজি প্যারামিটার ব্যবহার করেছে (link) \n\"AI Index Report 2024 – Artificial Intelligence Index\"। aiindex.stanford.edu। সংগ্রহের তারিখ ২০২৪-০৫-০৫। \nFrank, Michael C. (২৭ জুন ২০২৩)। \"Baby steps in evaluating the capacities of large language models\"। Nature Reviews Psychology। 2 (8): 451–452। আইএসএসএন 2731-0574। এসটুসিআইডি 259713140 । ডিওআই:10.1038/s44159-023-00211-x। সংগ্রহের তারিখ ২ জুলাই ২০২৩।"}